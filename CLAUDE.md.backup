# Claude Code Instructions for QuantConnect Trading Bot

This is a Python-based algorithmic trading project built for QuantConnect's LEAN platform. The project is designed for semi-autonomous development with Claude Code.

---

## ğŸ“š **NEW**: Centralized Documentation (Nov 30, 2025)

All project documentation has been reorganized for better clarity and navigation:

### **Start Here**
- [ğŸ“Š Project Status Dashboard](docs/PROJECT_STATUS.md) - Current state, metrics, next steps
- [ğŸ¯ Implementation Tracker](docs/IMPLEMENTATION_TRACKER.md) - Current sprint tasks (WHAT TO WORK ON NOW)
- [ğŸš€ Quick Start Guide](docs/QUICK_START.md) - Get up and running fast
- [ğŸ“ Documentation Index](docs/README.md) - All documentation organized by category

### **For Current Work**
**Current Sprint**: Integration Phase (Week 1)
**Top Priority**: Create main hybrid algorithm ([Task 1](docs/IMPLEMENTATION_TRACKER.md#task-1-create-main-hybrid-algorithm))

**Key Tasks This Sprint**:
1. ğŸ”´ Create `algorithms/hybrid_options_bot.py` - Integrate all 9 modules
2. ğŸ”´ Implement `api/rest_server.py` - FastAPI server for UI
3. ğŸ”´ Run initial backtest - Verify system works
4. ğŸ”´ Fix critical bugs - Address backtest issues

**See**: [Implementation Tracker](docs/IMPLEMENTATION_TRACKER.md) for detailed task descriptions

---

## ğŸ”„ **CRITICAL**: RIC Loop Workflow v5.1 (Guardian)

**For ALL complex tasks (multi-file changes, new features, refactoring), use the RIC Loop with STRICT SEQUENTIAL EXECUTION:**

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              RIC LOOP v5.1 (5 Phases)                               â”‚
â”‚                         STRICT SEQUENTIAL EXECUTION                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                      â”‚
â”‚   [I{iter}/{max}] P0 â†’ P1 â†’ P2 â†’ P3 â†’ P4 â†’ Loop/Exit                               â”‚
â”‚                    â†“     â†“     â†“     â†“     â†“                                        â”‚
â”‚                RESEARCH PLAN BUILD VERIFY REFLECT                                    â”‚
â”‚                                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ P0/P1/P2 REMAIN?     â”‚                        â”‚ ALL RESOLVED +               â”‚  â”‚
â”‚   â”‚ OR iteration < 3?    â”‚                        â”‚ iteration >= 3?              â”‚  â”‚
â”‚   â”‚                      â”‚                        â”‚                              â”‚  â”‚
â”‚   â”‚ â†’ LOOP to Phase 0    â”‚                        â”‚ â†’ EXIT ALLOWED               â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                                      â”‚
â”‚   Iteration: [1] [2] [3] [4] [5]   â† **Min 3**, Max 5, ALL P0-P2 REQUIRED          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Quick Reference (5 Phases)

| Phase | Name | Key Action | Gate |
|-------|------|------------|------|
| **P0** | Research | WebSearch + persist every 3 | 3+ timestamped sources |
| **P1** | Plan | P0/P1/P2/[OUT] tasks | All tasks prioritized |
| **P2** | Build | Atomic commits (1-5 files) | Tests with each change |
| **P3** | Verify | Tests â†’ Coverage â†’ Lint | All pass, >70% coverage |
| **P4** | Reflect | Classify gaps â†’ Decide | Loop decision made |

### CRITICAL Rules (v4.5)

1. **STRICT SEQUENTIAL**: Execute P0â†’P1â†’P2â†’P3â†’P4 in order, NO SKIPPING
2. **LOG EVERY PHASE**: Format: `[I{iter}/{max}][P{phase}] PHASE_NAME`
3. **MINIMUM 3 ITERATIONS**: Cannot exit before completing 3 full loops
4. **ALL P0/P1/P2 REQUIRED**: P2 is NOT optional - must be completed before exit
5. **ALL loops go to P0**: Research first, then implement
6. **Persist Research**: Save to docs/research/ every 3 searches

### Iteration Limits

| Limit | Value | Rationale |
|-------|-------|-----------|
| **Minimum** | **3 iterations** | Ensures thorough implementation |
| Maximum | 5 iterations | Prevents infinite loops |
| Plateau | 2 consecutive | Exit if no new insights |

### Loop Decision Rules (Phase 4)

```text
1. IF iteration < 3         â†’ LOOP (minimum 3 iterations)
2. ELIF P0 insights > 0     â†’ LOOP (critical gaps)
3. ELIF P1 insights > 0     â†’ LOOP (important items)
4. ELIF P2 insights > 0     â†’ LOOP (P2 is REQUIRED)
5. ELIF iteration >= 5      â†’ FORCED EXIT (max reached)
6. ELSE                     â†’ EXIT ALLOWED
```

### Exit Finalization (REQUIRED)

**Before exiting Phase 4 (Reflect), complete the finalization checklist:**

| Category | Checks |
|----------|--------|
| **Bug Finding** | Run tests, check syntax, review TODOs, remove debug code |
| **Missing Files** | Verify all planned files exist, imports work, dependencies listed |
| **Test Coverage** | Tests for new code, edge cases covered, >70% coverage |
| **Documentation** | Upgrade doc complete, CLAUDE.md updated, docstrings added |
| **Cross-Reference** | Related files updated, configs match, no stale references |
| **Cleanup** | Git status clean, no temp files, branch ready |

**NEVER exit without completing finalization. This ensures each upgrade is production-ready.**

### When to Use

**USE RIC Loop** for:

- New features (multi-file)
- Refactoring (multiple components)
- Architecture changes
- Complex bug fixes
- **Research-required implementations** (uncertain approach)

**SKIP entirely** for:

- Simple bug fixes (single file)
- Documentation-only changes
- Configuration updates

### v4.5 Safety Features

| Feature | Description |
|---------|-------------|
| **Hallucination Detection** | 5-category taxonomy check before commits |
| **Convergence Detection** | Multi-metric tracking (insight rate, fix success, code churn) |
| **Confidence Calibration** | Per-phase 0-100% confidence ratings |
| **Safety Throttles** | Tool call limits, time limits, failure limits |
| **Decision Tracing** | Structured JSON logs for meta-debugging |
| **Research Enforcement** | Timestamp validation, auto-persist every 3 searches |

### CLI Commands

```bash
# Initialize session
python3 .claude/hooks/core/ric.py init 5

# Session management
python3 .claude/hooks/core/ric.py status        # Show current status
python3 .claude/hooks/core/ric.py advance       # Advance to next phase
python3 .claude/hooks/core/ric.py can-exit      # Check if can exit
python3 .claude/hooks/core/ric.py end           # End session (if allowed)

# Insights and tracking
python3 .claude/hooks/core/ric.py add-insight P0 "Description"   # Add insight
python3 .claude/hooks/core/ric.py resolve INS-001 "Resolution"   # Resolve insight
python3 .claude/hooks/core/ric.py insights      # List all insights
python3 .claude/hooks/core/ric.py confidence 0 85 "Notes"        # Record confidence

# Quality gates
python3 .claude/hooks/core/ric.py check-gate 0  # Check gate criteria
python3 .claude/hooks/core/ric.py security      # Security check for secrets
python3 .claude/hooks/core/ric.py convergence   # Check convergence status

# Monitoring
python3 .claude/hooks/core/ric.py throttles     # Show throttle status
python3 .claude/hooks/core/ric.py research      # Research enforcement status
python3 .claude/hooks/core/ric.py decisions     # Show decision trace

# Machine-parseable output
python3 .claude/hooks/core/ric.py json          # JSON status output
python3 .claude/hooks/core/ric.py sync          # Sync to claude-progress.txt
python3 .claude/hooks/core/ric.py summary       # Generate iteration summary

# Help
python3 .claude/hooks/core/ric.py help          # Show all commands
python3 .claude/hooks/core/ric.py demo          # Show format examples
```

### Key Files

| File | Purpose |
|------|---------|
| `.claude/hooks/core/ric.py` | Main RIC v5.1 Guardian (~6700 lines) |
| `.claude/hooks/research/research_saver.py` | Research/upgrade document creator (~1200 lines) |
| `.claude/hooks/agents/agent_orchestrator.py` | Multi-agent orchestration engine (~1000 lines) |
| `.claude/RIC_CONTEXT.md` | Quick reference |
| `.claude/state/ric.json` | Session state (auto-managed) |
| `.claude/templates/` | Document templates (upgrade, research, insight, guide) |
| `.claude/scratch/ric_v4_ideas.md` | Design notes and research (historical) |

### Research-Backed Patterns

| Pattern | Source | RIC Implementation |
|---------|--------|-------------------|
| **SELF-REFINE** | OpenReview | Actionable feedback templates in fix prompts |
| **CoCoGen** | arXiv | Static analysis (lint â†’ types â†’ tests) order |
| **SAGE** | ScienceDirect | Independent checker verification (2.26x improvement) |
| **ReVeal** | arXiv | Self-constructed test cases |
| **PairCoder** | arXiv | Multi-plan exploration in PLAN phase |

### Full Workflow Documentation

**See**: [RIC_CONTEXT.md](.claude/RIC_CONTEXT.md) for quick reference
**See**: [UPGRADE-012.3](docs/research/UPGRADE-012.3-META-RIC-LOOP.md) for design rationale
**See**: [ric_v4_ideas.md](.claude/scratch/ric_v4_ideas.md) for historical research findings
**Research**: [MetaAgent](https://arxiv.org/html/2508.00271v2), [Self-Refine](https://arxiv.org/abs/2303.17651) for research basis

---

## ğŸš¨ **MANDATORY**: Thorough Action Protocol (TAP)

**THIS SECTION IS NON-NEGOTIABLE. EVERY CLAUDE AGENT MUST FOLLOW THESE RULES.**

### The Golden Rule

```
LOG â†’ CHECK â†’ TEST â†’ INTEGRATE â†’ VERIFY INTEGRATION â†’ LOG RESULT
```

### Required for EVERY Change

| Step | Action | Required Output |
|------|--------|-----------------|
| **1. LOG START** | Log what you're about to do | `[TAP] Starting: <action description>` |
| **2. CHECK** | Verify prerequisites exist | List files/functions that must exist |
| **3. IMPLEMENT** | Make the change | Show the actual code change |
| **4. TEST** | Run relevant tests | `pytest <test_file> -v` output |
| **5. INTEGRATE** | Wire into existing code | Show import/usage added |
| **6. VERIFY** | Confirm integration works | `python -c "from X import Y"` |
| **7. LOG END** | Document what was done | `[TAP] Complete: <result summary>` |

### Logging Requirements

**Every action MUST be logged to `claude-progress.txt`:**

```markdown
### [TAP] <timestamp> - <action>
- **What**: <description of change>
- **Files**: <list of files modified>
- **Tests**: <PASS/FAIL with count>
- **Integration**: <VERIFIED/FAILED>
- **Notes**: <any issues or observations>
```

### Never Skip These

1. **NEVER** mark a task complete without running tests
2. **NEVER** create a file without integrating it
3. **NEVER** integrate without verifying the import works
4. **NEVER** commit without logging what was changed
5. **NEVER** assume something works - verify it

### Verification Commands

```bash
# After creating a new module
python3 -c "from <module> import <class>; print('OK')"

# After modifying existing code
python3 -m pytest <relevant_test> -v --tb=short

# After any change
python3 -c "import <modified_module>; print('Import OK')"
```

### If Tests Fail

1. **LOG** the failure immediately
2. **DO NOT** move to next task
3. **FIX** the failing test
4. **RE-RUN** to confirm fix
5. **LOG** the resolution

### Integration Checklist

Before marking ANY task complete:

- [ ] File exists and is syntactically valid
- [ ] All imports resolve without error
- [ ] Unit tests pass
- [ ] Integration with existing code verified
- [ ] Changes logged to progress file
- [ ] No regressions in related tests

### Enforcement

> âš ï¸ **VIOLATION OF TAP = INCOMPLETE WORK** - Do not proceed to the next task.

---

## Project Overview

- **Purpose**: Semi-autonomous options trading bot with LLM-powered analysis
- **Platform**: QuantConnect / LEAN Engine with Charles Schwab brokerage
- **Language**: Python 3.10+
- **Testing**: pytest with 70% minimum coverage
- **UI**: PySide6 trading dashboard

## Core Capabilities

1. **LLM Integration**: FinBERT + GPT-4o + Claude ensemble for sentiment analysis
2. **Options Scanner**: Underpriced options detection using Greeks and IV analysis
3. **Movement Scanner**: 2-4% movers with news corroboration
4. **Profit-Taking**: Graduated selling at +100%, +200%, +400%, +1000%
5. **Smart Execution**: Auto cancel/replace with configurable max bid increase
6. **Technical Analysis**: VWAP, RSI, MACD, CCI, Bollinger, OBV, Ichimoku

## CRITICAL: Safety-First Development

**NEVER deploy untested code to live trading.** This project enforces a strict testing pipeline:

1. **Local Tests** â†’ Unit tests must pass
2. **Validation** â†’ Algorithm validator must approve
3. **Backtest** â†’ Cloud backtest must complete successfully
4. **Paper Trading** â†’ Paper trading validation required
5. **Live** â†’ Only after all stages pass

### Pre-Deployment Checklist

Before deploying to paper trading or live:

#### Code Quality

- [ ] All unit tests pass (`pytest tests/ -v`)
- [ ] Code coverage > 70% (`pytest --cov=. --cov-fail-under=70`)
- [ ] No linting errors (`ruff check .`)
- [ ] Type checking clean (`mypy --config-file mypy.ini`)
- [ ] No security vulnerabilities (GitLeaks clean)

#### Documentation

- [ ] CLAUDE.md updated (if workflow changed)
- [ ] ADR created (if architecture decision made)
- [ ] Code comments adequate for complex logic

#### Trading Safety

- [ ] Circuit breaker integration verified
- [ ] Kill switch tested and functional
- [ ] Position limits enforced
- [ ] Risk parameters within bounds

#### Validation

- [ ] Algorithm validator passes
- [ ] Backtest metrics meet targets (Sharpe > 1.0, Drawdown < 20%)
- [ ] Paper trading behavior matches backtest

#### Approval

- [ ] Human review completed
- [ ] Explicit deployment approval obtained

### Before Making Changes

Always create a backup before modifying algorithm files:
```python
from scripts.backup_manager import create_pre_change_backup
create_pre_change_backup("algorithms/my_algo.py", "adding new indicator")
```

## Directory Structure

### Claude Code Infrastructure (.claude/)

```
.claude/
â”œâ”€â”€ hooks/                  # Claude Code hooks (organized by category)
â”‚   â”œâ”€â”€ core/              # Critical hooks (RIC, session, protection)
â”‚   â”‚   â”œâ”€â”€ ric.py         # RIC Loop v5.1 Guardian (~6700 lines)
â”‚   â”‚   â”œâ”€â”€ session_stop.py
â”‚   â”‚   â”œâ”€â”€ pre_compact.py
â”‚   â”‚   â”œâ”€â”€ protect_files.py
â”‚   â”‚   â””â”€â”€ hook_utils.py
â”‚   â”œâ”€â”€ validation/        # Code and document validators
â”‚   â”œâ”€â”€ research/          # Research tracking hooks
â”‚   â”œâ”€â”€ trading/           # Trading-specific hooks
â”‚   â”œâ”€â”€ formatting/        # Code formatting hooks
â”‚   â”œâ”€â”€ agents/            # Agent orchestration hooks
â”‚   â””â”€â”€ deprecated/        # Legacy hooks (do not use)
â”œâ”€â”€ state/                 # Runtime state files
â”‚   â”œâ”€â”€ ric.json           # RIC Loop state
â”‚   â”œâ”€â”€ doc_updates.json   # Documentation tracking
â”‚   â””â”€â”€ circuit_breaker.json
â”œâ”€â”€ config/                # Configuration files
â”‚   â””â”€â”€ agents.json        # Agent configuration
â”œâ”€â”€ commands/              # Slash commands
â”œâ”€â”€ templates/             # Document templates
â”œâ”€â”€ settings.json          # Claude Code settings
â””â”€â”€ registry.json          # Hook/script registry
```

### Trading Infrastructure

```
algorithms/     # Trading algorithms (QuantConnect compatible)
â”œâ”€â”€ options_trading_bot.py  # Main algorithm with Schwab integration

config/         # Configuration management
â”œâ”€â”€ settings.json           # All adjustable parameters
â”œâ”€â”€ __init__.py            # ConfigManager class

llm/            # LLM integration
â”œâ”€â”€ agents/                # LLM trading agents (primary)
â”œâ”€â”€ base.py                # Base classes (Sentiment, NewsItem)
â”œâ”€â”€ sentiment.py           # FinBERT + Simple analyzers
â”œâ”€â”€ providers.py           # OpenAI + Anthropic providers
â”œâ”€â”€ ensemble.py            # Weighted ensemble predictions
â””â”€â”€ news_analyzer.py       # News fetching and analysis

scanners/       # Market scanners
â”œâ”€â”€ options_scanner.py     # Underpriced options detection
â”œâ”€â”€ movement_scanner.py    # Price movement + news correlation

execution/      # Order execution
â”œâ”€â”€ profit_taking.py       # Graduated profit-taking model
â”œâ”€â”€ smart_execution.py     # Cancel/replace execution model

indicators/     # Technical indicators
â”œâ”€â”€ volatility_bands.py    # Keltner, Bollinger
â”œâ”€â”€ technical_alpha.py     # VWAP, RSI, MACD, CCI, OBV, Ichimoku

ui/             # PySide6 dashboard
â”œâ”€â”€ widgets.py             # Reusable UI components
â”œâ”€â”€ dashboard.py           # Main trading dashboard

models/         # Risk models
â”œâ”€â”€ risk_manager.py        # Position sizing, limits
â”œâ”€â”€ circuit_breaker.py     # Trading halt safety

agents_deprecated/  # DEPRECATED: Use llm/agents/ instead

utils/          # Helper functions
scripts/        # Utility scripts (backup, validation, pipeline)
tests/          # Unit and integration tests
docs/prompts/   # Prompt framework (versioned)
.backups/       # Automatic backups (DO NOT DELETE)
```

## Key Commands

### RIC Loop Commands (Complex Tasks)

| Command | Description |
|---------|-------------|
| `/ric-start <task>` | Start new Enhanced RIC Loop session with templates |
| `/ric-research <topic>` | Begin Phase 0 research with keyword expansion |
| `/ric-introspect` | Run Phase 5-6 introspection and metacognition |
| `/ric-converge` | Calculate convergence score and decide next step |

### Development Commands

| Command | Description |
|---------|-------------|
| `/new-algorithm <description>` | Create a new trading algorithm |
| `/backtest <algorithm>` | Run a backtest |
| `/run-tests [pattern]` | Run test suite |
| `/analyze-strategy <algorithm>` | Review strategy code |
| `/lint [target]` | Run code quality checks |

### Multi-Agent Orchestration Commands

| Command | Description | Agents |
|---------|-------------|--------|
| `/agents auto <task>` | **Intelligent auto-routing** - best agents for any task | Auto |
| `/agent-quick <task>` | Single fast agent dispatch | 1 |
| `/agent-swarm <topic>` | Massive parallel exploration | 8 |
| `/agent-consensus <decision>` | Multi-agent voting/decision | 3 |
| `/agent-implement <feature>` | Full implementation pipeline | 4 |
| `/agent-compare <options>` | Compare approaches (A vs B) | 2-3 |
| `/agent-status` | Show orchestration statistics | - |
| `/parallel-review <files>` | Code review (security, types, tests, arch) | 4 |
| `/multi-search <query>` | Search code, docs, tests | 3 |
| `/trading-review <files>` | Trading safety review | 3 |

**Quick Examples:**

```bash
/agents auto find all error handling code     # Auto-select best agents
/agent-quick find circuit breaker usage       # Single fast agent
/agent-swarm authentication                   # 8-agent deep exploration
/agent-consensus should we refactor auth      # 3-agent voting
/agent-implement add IV rank filter           # Full pipeline
/agent-compare Redis vs Memcached             # Compare options
```

### Registry & Documentation Commands

| Command | Description |
|---------|-------------|
| `/sync-registry` | Sync hooks, scripts, commands registry |
| `/validate-docs` | Validate research documentation |
| `/save-research <type> <title>` | Save research, upgrades, insights with proper naming |

### Research Saver Commands

| Command | Description |
|---------|-------------|
| `/save-research upgrade "Title"` | Create new upgrade guide (auto-assigns next number) |
| `/save-research research "Topic"` | Create research document |
| `/save-research insight "Title"` | Create timestamped insight |
| `/save-research guide "Title"` | Create how-to guide |
| `/save-research next` | Get next available upgrade number |
| `/save-research list` | List all documentation files |
| `/save-research check "filename"` | Check if filename is available |

**Examples:**

```bash
/save-research upgrade "Agent Memory System"    # Creates UPGRADE-018-AGENT-MEMORY-SYSTEM.md
/save-research research "LLM Patterns"          # Creates LLM-PATTERNS-RESEARCH.md
/save-research insight "Context Optimization"   # Creates INSIGHT-2025-12-04-CONTEXT-OPTIMIZATION.md
```

### Quick Scripts

```bash
python scripts/sync_claude_registry.py      # Sync registry & settings
python scripts/validate_research_docs.py    # Validate research docs
python scripts/create_research_doc.py "X" --topic Y  # Create research doc

# Research Saver CLI
python3 .claude/hooks/research/research_saver.py help           # Show help
python3 .claude/hooks/research/research_saver.py next           # Next upgrade number
python3 .claude/hooks/research/research_saver.py list           # List all docs
python3 .claude/hooks/research/research_saver.py template upgrade  # Print upgrade template
```

## Autonomous Testing Pipeline

The project includes an automated testing pipeline that runs on every push:

### GitHub Actions Workflows

| Workflow | Purpose | Trigger |
|----------|---------|---------|
| `autonomous-testing.yml` | Full test pipeline | Push to develop/feature |
| `paper-trading.yml` | Deploy to paper trading | Manual (after approval) |
| `branch-protection.yml` | Enforce branching rules | PRs to main/develop |
| `deploy.yml` | Deploy to QuantConnect | Push to main |

### Testing Stages

1. **Validation**: Syntax, structure, risk patterns
2. **Unit Tests**: All test files with `@pytest.mark.unit`
3. **Integration Tests**: Full algorithm cycle tests
4. **Cloud Backtest**: QuantConnect backtest execution
5. **Paper Trading Gate**: Final approval check

## Algorithm Development Workflow

### 1. Create Feature Branch
```bash
git checkout -b feature/my-new-strategy
```

### 2. Develop and Test Locally
```bash
# Run validation
python scripts/algorithm_validator.py algorithms/my_strategy.py

# Run tests
pytest tests/ -v -m unit
```

### 3. Push and Let CI Run
```bash
git push origin feature/my-new-strategy
```

### 4. Review Autonomous Test Results
- Check GitHub Actions for test results
- Review backtest performance
- Verify all safety gates pass

### 5. Merge to Develop
- Create PR to develop
- Require passing tests
- Review code changes

### 6. Paper Trading
- Use paper-trading.yml workflow
- Monitor for specified duration
- Verify behavior matches expectations

### 7. Production (Main)
- Merge develop to main
- Deploy workflow triggers automatically

## QuantConnect Essentials

### Compute Node Selection

This project is configured for optimal QuantConnect compute nodes:

| Node Type | Model | Cores | RAM | Cost/Month | Purpose |
|-----------|-------|-------|-----|------------|---------|
| **Backtesting** | **B8-16** | 8 @ 4.9GHz | 16GB | $28 | Options data + multi-chain spreads |
| **Research** | **R8-16** | 8 @ 2.4GHz | 16GB | $14 | LLM ensemble + strategy exploration |
| **Live Trading** | **L2-4** | 2 @ 2.6GHz | 4GB | $50 | Real-time options trading |

Total monthly cost: $92/month

#### Why These Nodes?

- **B8-16**: High RAM for 500+ option contracts, 8 cores for Greeks calculations
- **R8-16**: Sufficient for LLM API calls (not local inference), best value for research
- **L2-4**: Dual-core for trading loop + scanners, colocated for <100ms latency

#### Analyze Algorithm Requirements

```bash
# Get automatic node recommendations
python scripts/deploy_with_nodes.py algorithms/options_trading_bot.py --analyze-only
```

#### Deploy with Node Selection

```bash
# Backtest deployment
python scripts/deploy_with_nodes.py algorithms/options_trading_bot.py --type backtest

# Live deployment
python scripts/deploy_with_nodes.py algorithms/options_trading_bot.py --type live --node L2-4
```

#### Resource Monitoring

The algorithm automatically monitors resources every 30 seconds:

```python
# Configured in config/settings.json
"quantconnect": {
  "monitoring": {
    "enabled": true,
    "check_interval_seconds": 30,
    "memory_warning_pct": 80,
    "memory_critical_pct": 90
  }
}
```

See [Compute Nodes Documentation](docs/infrastructure/COMPUTE_NODES.md) for complete guide.

### Algorithm Structure

```python
from AlgorithmImports import *

class MyAlgorithm(QCAlgorithm):
    def Initialize(self) -> None:
        # Python API uses snake_case for methods
        self.set_start_date(2020, 1, 1)
        self.set_end_date(2023, 12, 31)
        self.set_cash(100000)
        self.symbol = self.add_equity("SPY", Resolution.Daily).Symbol

    def OnData(self, data: Slice) -> None:
        # ContainsKey is a framework method (PascalCase exception)
        if not data.ContainsKey(self.symbol):
            return
        # Trading logic here
```

### Common APIs

**Note**: Python API uses snake_case for methods (not C# PascalCase)

| Method | Purpose |
|--------|---------|
| `self.add_equity(ticker, resolution)` | Subscribe to stock data |
| `self.rsi(symbol, period)` | Create RSI indicator |
| `self.set_holdings(symbol, weight)` | Set position size |
| `self.liquidate(symbol)` | Close position |
| `self.Portfolio[symbol].Invested` | Check if holding (Portfolio is PascalCase) |
| `self.set_warm_up(periods)` | Warm up indicators |

### Critical Patterns

**Always validate data:**
```python
# ContainsKey and IsReady are framework properties (PascalCase exceptions)
if data.ContainsKey(self.symbol) and self.indicator.IsReady:
    # Safe to proceed
```

**Always warm up indicators:**
```python
# Python API uses snake_case for methods
self.set_warm_up(self.lookback_period)
# In OnData:
# IsWarmingUp is a framework property (PascalCase exception)
if self.IsWarmingUp:
    return
```

### CRITICAL: Platform-Specific Limitations

#### Charles Schwab Brokerage

**CRITICAL LIMITATION**: Charles Schwab allows **ONLY ONE algorithm per account**.

- Deploying a second algorithm automatically stops the first
- All trading strategies must be combined into a single algorithm
- Cannot run separate algorithms for different strategies simultaneously
- OAuth re-authentication required approximately weekly

```python
# WRONG - Second algorithm will stop first
# Algorithm 1: Options scanner
# Algorithm 2: Equity momentum

# CORRECT - Combine into single algorithm
class UnifiedTradingBot(QCAlgorithm):
    def Initialize(self):
        self.SetBrokerageModel(BrokerageName.CharlesSchwab, AccountType.Margin)
        # Combine all strategies in one algorithm
        self.options_strategy = OptionsScanner()
        self.equity_strategy = EquityMomentum()
```

#### IV-Based Greeks (LEAN PR #6720)

**CRITICAL UPDATE**: Greeks now use implied volatility - **NO warmup required**.

```python
# Immediate access to Greeks (no warmup needed)
for contract in option_chain:
    delta = contract.Greeks.Delta
    gamma = contract.Greeks.Gamma
    theta_per_day = contract.Greeks.ThetaPerDay  # Daily theta
    iv = contract.ImpliedVolatility

    # Greeks available immediately upon data arrival
    if 0.25 < abs(delta) < 0.35 and iv > 0.20:
        # Trade logic
```

**Key Changes:**

- Greeks calculated using IV from option prices
- Values match Interactive Brokers and major brokerages
- Default models: Black-Scholes (European), Bjerksund-Stensland (American)
- No warmup period required for Greeks calculations

#### Multi-Leg Options with ComboOrders

**For butterflies, condors, spreads - use ComboOrders for atomic execution.**

âœ… **CONFIRMED: ComboOrders are FULLY SUPPORTED on Charles Schwab** (as of 2025-11-30)

```python
# Long call butterfly - atomic execution
atm_strike = self.get_atm_strike(underlying_price)
legs = [
    Leg.Create(self.get_call(atm_strike - 5), 1),   # Buy lower
    Leg.Create(self.get_call(atm_strike), -2),      # Sell ATM
    Leg.Create(self.get_call(atm_strike + 5), 1),   # Buy upper
]

# All legs fill together or none fill
# Uses net debit/credit pricing (NOT individual leg limits)
self.ComboLimitOrder(legs, quantity=1, limit_price=net_debit)
```

**Available ComboOrder Types:**

| Order Type | Schwab Support | Description |
|-----------|---------------|-------------|
| `ComboMarketOrder()` | âœ… SUPPORTED | Execute at market |
| `ComboLimitOrder()` | âœ… SUPPORTED | Net limit price across all legs |
| `ComboLegLimitOrder()` | âŒ NOT supported | Individual leg limits (not available on Schwab) |

**Important for Charles Schwab:**
- Use `ComboLimitOrder()` with net debit/credit pricing
- Do NOT use `ComboLegLimitOrder()` - individual leg limits not supported
- Do NOT specify `order_price` parameter in `Leg.Create()` calls

**Benefits:**

- Automatic strategy detection (LEAN has 24 files for multi-leg matching)
- Atomic execution (all-or-nothing fills)
- Single commission per combo
- Prevents holding unbalanced positions
- **Your two-part spread strategy works with Schwab using ComboLimitOrder!**

## Risk Management Integration

Use the RiskManager class from `models/risk_manager.py`:

```python
from models import RiskManager, RiskLimits

# Configure limits
limits = RiskLimits(
    max_position_size=0.25,      # 25% max per position
    max_daily_loss=0.03,         # 3% daily loss limit
    max_drawdown=0.10,           # 10% max drawdown
    max_risk_per_trade=0.02,     # 2% risk per trade
)

risk_manager = RiskManager(starting_equity=100000, limits=limits)
```

## Code Quality Requirements

- Type hints on all methods (Python 3.8+ compatible: `List[X]` not `list[X]`)
- Google-style docstrings
- Max 100 characters per line
- No look-ahead bias
- Defensive data access

**For detailed standards, see:**

- [Development Best Practices](docs/development/BEST_PRACTICES.md) - Trading safety, risk management, backtesting
- [Coding Standards](docs/development/CODING_STANDARDS.md) - Style guide, type hints, documentation

---

## Test-Driven Development (TDD)

Follow the Red-Green-Refactor cycle for all new features:

1. **RED**: Write a failing test first
2. **GREEN**: Write minimal code to pass the test
3. **REFACTOR**: Improve code quality while tests pass

### Test Pyramid Targets

| Test Type | Target | Purpose |
|-----------|--------|---------|
| Unit | 50% | Fast, isolated component tests |
| Integration | 30% | Module interaction tests |
| E2E | 20% | Full system validation |

### Key Principles

- Test **behavior**, not implementation details
- Use fixtures for reusable setup/teardown
- Minimum 70% coverage required
- Run tests before every commit

```python
# Good: Test behavior
def test_circuit_breaker_halts_on_daily_loss():
    breaker = CircuitBreaker(max_daily_loss=0.03)
    breaker.record_loss(0.035)
    assert not breaker.can_trade()

# Bad: Test implementation
def test_circuit_breaker_internal_state():
    breaker = CircuitBreaker()
    assert breaker._daily_loss_counter == 0  # Don't test internals
```

---

## Code Review Checklist

### For Authors (Before Submitting PR)

- [ ] PR is < 400 lines (split if larger)
- [ ] All tests pass locally
- [ ] Added tests for new functionality
- [ ] Updated documentation if needed
- [ ] No secrets or credentials committed
- [ ] Type hints on all new methods
- [ ] Ran `ruff check .` with no errors

### For Reviewers

- [ ] **Logic**: Does the code do what it claims?
- [ ] **Security**: OWASP Top 10 vulnerabilities checked?
- [ ] **Performance**: Any obvious bottlenecks?
- [ ] **Maintainability**: Will future devs understand this?
- [ ] **Edge cases**: Are error conditions handled?
- [ ] **Tests**: Do tests cover the critical paths?

### AI-Generated Code Review (Critical)

**62% of AI-generated code contains vulnerabilities.** Extra scrutiny required:

- [ ] Verify no hardcoded credentials or secrets
- [ ] Check for SQL injection, XSS, command injection
- [ ] Validate input/output handling
- [ ] Confirm error handling is appropriate
- [ ] Review for business logic correctness

---

## Technical Debt Budget

Allocate **15-20% of each sprint** for debt reduction:

- Refactoring legacy code
- Updating dependencies
- Improving test coverage
- Documentation updates

### Tracking Technical Debt

Use `tech-debt` label in GitHub Issues. Include:

- Description of the debt
- Impact if not addressed
- Estimated effort to fix
- Priority (P0-P2)

### Monthly Debt Review

Schedule monthly review to:

1. Assess current debt level
2. Prioritize high-impact items
3. Allocate sprint capacity
4. Track debt trends over time

**Why This Matters**: Without a debt budget, organizations spend 40% of IT budgets on maintenance (Gartner 2025).

---

## Dependency Security

### Automated Vulnerability Scanning

Run security scans in CI/CD:

```yaml
# In GitHub Actions
- name: Audit dependencies
  run: |
    pip install pip-audit
    pip-audit -r requirements.txt
```

### Pre-commit Security Hooks

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/pyupio/safety
    rev: 2.3.5
    hooks:
      - id: safety
        args: [check, --full-report]
```

### Keep Dependencies Updated

- Enable Dependabot for automatic security updates
- Review and merge security PRs within 48 hours
- Test thoroughly after dependency updates

### Never Ignore

- Known vulnerabilities in direct dependencies
- Outdated packages with security patches available
- Dependencies with no recent maintenance

## Audit Logging (Trading Compliance)

Trading systems require comprehensive audit logging for regulatory compliance:

**Required Log Fields** (for every trading action):

| Field | Description | Example |
|-------|-------------|---------|
| `timestamp` | ISO 8601 with timezone | `2025-12-02T14:30:00Z` |
| `actor` | User or system identifier | `algorithm:hybrid_bot` |
| `action` | What happened | `ORDER_SUBMITTED` |
| `resource` | Affected entity | `SPY_241220C450` |
| `details` | Action-specific data | `{"qty": 10, "price": 4.50}` |
| `outcome` | Result | `SUCCESS` or `FAILED` |

**Compliance Requirements**:

| Regulation | Retention | Notes |
|------------|-----------|-------|
| SOX | 7 years | Financial reporting controls |
| PCI DSS 4.0 | 12 months (3 months accessible) | If handling card data |
| General Best Practice | 12+ months | Minimum for trading systems |

**Implementation**:

```python
from utils.structured_logger import AuditLogger

audit = AuditLogger()

# Log trading actions
audit.log_trade(
    action="ORDER_SUBMITTED",
    symbol="SPY",
    quantity=100,
    price=450.00,
    order_type="LIMIT",
    outcome="SUCCESS"
)
```

**Security**: Encrypt sensitive fields, sanitize PII, never log API keys or credentials.

## Disaster Recovery Basics

**Key Metrics**:

| Metric | Definition | Target |
|--------|------------|--------|
| RTO (Recovery Time Objective) | Max downtime allowed | <4 hours |
| RPO (Recovery Point Objective) | Max data loss allowed | <1 hour |

**Checklist**:

- [ ] Daily backups of configuration and state
- [ ] Weekly backup restoration test
- [ ] Documented recovery procedures
- [ ] Annual DR simulation drill
- [ ] Off-site backup storage

**Critical**: 43% of companies with major data loss never reopen. Test your backups regularly.

## Pre-Commit Hooks

Install pre-commit hooks to ensure code quality:
```bash
pip install pre-commit
pre-commit install
```

Hooks will run:
- Black formatter
- Flake8 linter
- MyPy type checker
- Algorithm validator
- Automatic backup

## Backup System

Backups are automatically created:
- Before any code change (via pre-commit)
- Before paper trading deployment
- Can be restored if issues occur

```python
from scripts.backup_manager import BackupManager

manager = BackupManager()
manager.list_backups()  # View all backups
manager.restore_file(Path("algorithms/my_algo.py"), backup_index=0)  # Restore latest
```

## Common Mistakes to Avoid

1. **Look-ahead bias**: Don't use future data in decisions
2. **Missing warmup**: Always warm up indicators
3. **Unchecked data access**: Verify data exists before using
4. **Over-optimization**: Avoid curve-fitting to historical data
5. **Ignoring costs**: Account for commissions and slippage
6. **No risk management**: Always include position limits and stops
7. **Skipping tests**: Never deploy without passing all test stages

## GitHub Integration

### Branch Strategy

| Branch | Purpose | Protection |
|--------|---------|------------|
| `main` | Production algorithms | Requires PR from develop |
| `develop` | Integration testing | Requires PR approval |
| `feature/*` | New features | None |
| `bugfix/*` | Bug fixes | None |
| `hotfix/*` | Urgent fixes | Can PR to main |

### Required Secrets

Add to GitHub repository settings:
- `QC_USER_ID`: QuantConnect user ID
- `QC_API_TOKEN`: QuantConnect API token

### Commit Message Conventions

This project follows [Conventional Commits](https://www.conventionalcommits.org/) for clear, parseable commit history:

**Format**: `<type>(<scope>): <description>`

| Type | Description | Example |
|------|-------------|---------|
| `feat` | New feature | `feat(scanner): add IV rank filter` |
| `fix` | Bug fix | `fix(execution): correct fill price calculation` |
| `docs` | Documentation | `docs(readme): update setup instructions` |
| `style` | Formatting | `style: fix indentation in risk_manager` |
| `refactor` | Code restructure | `refactor(llm): simplify ensemble logic` |
| `perf` | Performance | `perf(scanner): optimize option chain processing` |
| `test` | Tests | `test(circuit_breaker): add halt trigger tests` |
| `build` | Build/deps | `build: update numpy to 1.26` |
| `ci` | CI/CD | `ci: add security scanning workflow` |
| `chore` | Maintenance | `chore: clean up unused imports` |

**Breaking Changes**: Add `!` after type: `feat(api)!: change response format`

**Scope**: Optional, use module name (e.g., `scanner`, `execution`, `llm`, `ui`)

### Code Ownership (CODEOWNERS)

Critical paths require senior review via `.github/CODEOWNERS`:

```text
# Core trading logic - requires senior review
/algorithms/ @senior-dev @tech-lead
/execution/ @senior-dev @tech-lead

# Risk management is critical
/models/risk_manager.py @tech-lead
/models/circuit_breaker.py @tech-lead

# LLM integration
/llm/ @senior-dev

# Tests - any team member
/tests/ @dev-team
```

**Ownership Responsibilities**:
- Review all PRs touching owned paths
- Maintain documentation for owned modules
- Respond to review requests within 24 hours

## Environment Setup

1. Clone repository
2. Create virtual environment: `python -m venv venv`
3. Activate: `source venv/bin/activate`
4. Install: `pip install -r requirements.txt && pip install -e .`
5. Copy `.env.example` to `.env` and configure
6. Install pre-commit: `pre-commit install`

## Autonomous Claude Code Workflow

This project is configured for autonomous development with Claude Code. The workflow uses graduated autonomy with safety layers.

### Permission Modes

- **Normal Mode**: Prompts for approval on changes (default)
- **Auto-Accept Mode**: Automatically approves edits and commands (Shift+Tab to cycle)
- **Plan Mode**: Read-only research mode

For autonomous development in Docker, use `--dangerously-skip-permissions` flag (container only).

### Model Selection

| Model | Use Case | Cost |
|-------|----------|------|
| Claude Sonnet 4 | Default development, fast iteration | $3/$15 per MTok |
| Claude Opus 4 | Deep analysis, multi-hour sessions | $15/$75 per MTok |

Use Sonnet for most tasks. Switch to Opus for:
- Architectural refactoring
- Analyzing strategy underperformance
- Multi-hour autonomous sessions

### Thinking Triggers

For complex reasoning tasks, use these prompts:
- `"think"` - Enable basic extended thinking
- `"ultrathink"` - Maximum reasoning tokens for deep analysis

### Autonomous Development Phases

**Phase 1: Development (Sandboxed)**
```bash
# No network access, strict isolation
docker-compose run sandbox
# OR
docker run --network=none --cap-drop ALL trading-sandbox pytest tests/
```

**Phase 2: Backtest Validation**
```bash
# Limited network for LEAN CLI
docker-compose run backtest
# Target metrics: Sharpe > 1.0, Drawdown < 20%
```

**Phase 3: Paper Trading**
```bash
# Network access to QuantConnect only
docker-compose run paper-trading
# Validates execution logic, NOT real-world performance
```

**Phase 4: Human Review Gate**
- REQUIRED before any live deployment
- Review backtest metrics and paper trading results
- Explicit approval needed

### Running the Full Pipeline

```bash
# Run complete autonomous pipeline
./scripts/run_pipeline.sh

# Analyze results (JSON output for Claude parsing)
python scripts/analyze_results.py --results-dir results/
```

### Structured Test Output

Test results are output as structured JSON for Claude iteration:

```json
{
  "pass_rate": 0.95,
  "failures": [{
    "test_name": "test_stop_loss_trigger",
    "expected": "position_closed=True",
    "actual": "position_closed=False",
    "relevant_lines": [45, 52],
    "suggested_investigation": "Check comparison operator"
  }],
  "actionable_recommendations": [
    "Fix test_stop_loss_trigger: Review stop loss logic at line 45"
  ]
}
```

### Convergence Criteria

Claude stops iterating when:
1. All tests pass (success)
2. 95%+ pass rate (acceptable)
3. Maximum iterations reached
4. No progress for 2+ iterations (stuck state)

## Overnight Autonomous Sessions

For extended 8+ hour autonomous development sessions, use the overnight session infrastructure.

**Related Documentation**:
- [Autonomous Agents Guide](docs/autonomous-agents/README.md) - Complete overnight session architecture
- [UPGRADE-011 Research](docs/research/UPGRADE-011-OVERNIGHT-SESSIONS.md) - Implementation details and research
- [Session Notes Template](scripts/templates/session-notes-template.md) - Relay-race context file

### Quick Start

```bash
# Basic overnight session
./scripts/run_overnight.sh "Implement feature X"

# Full autonomous overnight session (recommended)
./scripts/run_overnight.sh --continuous --with-recovery "Implement feature X"

# With Opus model for complex work
./scripts/run_overnight.sh --model opus --continuous --with-recovery "Major refactoring"

# View all options
./scripts/run_overnight.sh --help
```

### Overnight Session Options

| Flag | Description |
|------|-------------|
| `--model [sonnet\|opus]` | Select model (default: sonnet) |
| `--continuous` | **Work until ALL tasks complete** (blocks stop when tasks remain) |
| `--with-recovery` | Enable auto-resume on crash/disconnect |
| `--no-watchdog` | Disable watchdog (for debugging) |
| `--duration HOURS` | Max session hours (default: 10) |

### Continuous Mode (UPGRADE-011)

When `--continuous` flag is used:
1. **Stop hook checks** `claude-progress.txt` for pending tasks (`- [ ]` items)
2. **If tasks remain**, Claude continues working (exit code 2 blocks stop)
3. **Safety limit**: Max 10 continuation attempts per session
4. **Loop prevention**: `stop_hook_active` flag prevents infinite loops

```bash
# Enable continuous mode - Claude works until ALL tasks marked complete
export CONTINUOUS_MODE=1
./scripts/run_overnight.sh "Implement all features in checklist"
```

### Relay-Race Pattern

Context persists across sessions via `claude-session-notes.md`:

```markdown
# Claude Session Notes
## Current Goal
[Task description]

## Key Decisions Made
[Document architectural decisions]

## Important Discoveries
[Things learned that future sessions need]

## Next Steps
[What next session should focus on]
```

**How it works**:
1. Session notes file persists (not reset between sessions)
2. Each session reads notes to understand prior context
3. Update notes with discoveries and decisions before stopping
4. Works like a "relay baton" passed between sessions

### Autonomous Agent Documentation

Comprehensive autonomous agent documentation is available in `docs/autonomous-agents/`:

| Document | Purpose |
|----------|---------|
| [README.md](docs/autonomous-agents/README.md) | Main guide with architecture and patterns |
| [COMPARISON.md](docs/autonomous-agents/COMPARISON.md) | Tool and framework comparisons |
| [INSTALLATION.md](docs/autonomous-agents/INSTALLATION.md) | Step-by-step setup instructions |
| [TODO.md](docs/autonomous-agents/TODO.md) | Implementation checklist |

### Key Components

| Component | File | Purpose |
|-----------|------|---------|
| Watchdog | `scripts/watchdog.py` | External process monitoring safety limits |
| Startup Script | `scripts/run_overnight.sh` | Session initialization and management |
| Auto-Resume | `scripts/auto-resume.sh` | Crash recovery with exponential backoff |
| Checkpoint | `scripts/checkpoint.sh` | Git-based checkpointing and recovery |
| Stop Hook | `.claude/hooks/core/session_stop.py` | Session end handling, continuous mode |
| PreCompact Hook | `.claude/hooks/core/pre_compact.py` | Transcript backup before compaction |
| Session Notes | `claude-session-notes.md` | Relay-race context persistence |
| Progress File | `claude-progress.txt` | Task tracking and state |

### Overnight Decision Tree

```
START OVERNIGHT SESSION
        â”‚
        â”œâ”€â”€ Is task complex/multi-hour?
        â”‚   â”œâ”€â”€ YES â†’ Use --continuous --with-recovery --model opus
        â”‚   â””â”€â”€ NO  â†’ Use basic ./scripts/run_overnight.sh
        â”‚
        â”œâ”€â”€ During Session
        â”‚   â”œâ”€â”€ Update claude-progress.txt with [x] as tasks complete
        â”‚   â”œâ”€â”€ Update claude-session-notes.md with discoveries
        â”‚   â””â”€â”€ Git checkpoint every 15-20 minutes
        â”‚
        â”œâ”€â”€ On Stop Attempt (--continuous mode)
        â”‚   â”œâ”€â”€ Pending tasks in progress file?
        â”‚   â”‚   â”œâ”€â”€ YES â†’ Continue working (exit code 2)
        â”‚   â”‚   â””â”€â”€ NO  â†’ Normal stop, run cleanup
        â”‚   â””â”€â”€ Max attempts reached? â†’ Force stop
        â”‚
        â””â”€â”€ On Crash/Disconnect (--with-recovery mode)
            â”œâ”€â”€ Auto-resume monitors process
            â”œâ”€â”€ Exponential backoff with jitter
            â”œâ”€â”€ Read progress file for context
            â””â”€â”€ Resume where left off
```

### Safety Infrastructure

1. **External Watchdog**: Separate process monitors runtime, idle time, cost
2. **File Protection Hook**: Blocks access to `.env`, credentials, secrets
3. **Budget Tracking**: Configurable daily spending limits
4. **Checkpoint Commits**: Regular git commits preserve progress
5. **Progress File**: `claude-progress.txt` tracks session state
6. **Continuation Limit**: Max 10 stop-hook continuations
7. **Transcript Backup**: PreCompact hook saves full context before summarization

### Plan Limits (Max 20x Recommended)

| Metric | Limit |
|--------|-------|
| 5-hour prompts | 200-800 |
| Weekly Sonnet 4 | 240-480 hours |
| Weekly Opus 4 | 24-40 hours |

### Recovery Commands

```bash
# Create test-validated checkpoint
./scripts/checkpoint.sh auto

# Recover from failed session
./scripts/checkpoint.sh recover

# View checkpoints
./scripts/checkpoint.sh list

# Restore to checkpoint
./scripts/checkpoint.sh restore checkpoint-pre-refactor
```

### CRITICAL: Known Issues

**`deny` rules in settings.json are NOT enforced** (GitHub issues #6699, #6631).

Use PreToolUse hooks instead:
```json
{
  "hooks": {
    "PreToolUse": [{
      "matcher": "Edit|Write|Read",
      "hooks": [{
        "type": "command",
        "command": "python3 .claude/hooks/core/protect_files.py"
      }]
    }]
  }
}
```

## Circuit Breaker Safety

Use the TradingCircuitBreaker for autonomous trading safety:

```python
from models.circuit_breaker import TradingCircuitBreaker, create_circuit_breaker

# Create with default limits
breaker = create_circuit_breaker(
    max_daily_loss=0.03,      # 3% daily loss limit
    max_drawdown=0.10,        # 10% max drawdown
    max_consecutive_losses=5,  # Halt after 5 losses
    require_human_reset=True   # Require human to resume
)

# In trading loop
if not breaker.can_trade():
    return  # Trading halted

# Check conditions
breaker.check_daily_loss(portfolio.daily_pnl_pct)
breaker.check_drawdown(current_equity, peak_equity)

# Record trade results
breaker.record_trade_result(is_winner=True)

# Manual halt
breaker.halt_all_trading("Market conditions unusual")

# Reset requires authorization
breaker.reset(authorized_by="trader@example.com")
```

## Root Cause Analysis (RCA)

When production bugs or critical issues occur, follow the RCA process:

### When RCA is Required

- Production incidents affecting trading
- Financial loss due to bugs
- P0/P1 bugs found in testing
- Security vulnerabilities

### 5 Whys Method

Ask "Why?" iteratively to find the root cause:

```text
Problem: Order executed at wrong price
Why #1: Stale price data was used
Why #2: Price update handler wasn't called
Why #3: WebSocket reconnection failed silently
Why #4: No error logging for reconnection failures
Why #5: Reconnection logic added without tests
Root Cause: Missing test coverage for error paths
Fix: Add reconnection tests and error logging
```

### Post-RCA Actions

1. **Create regression test** in `tests/regression/`
2. **Update documentation** (CLAUDE.md, ADRs)
3. **Add to incident log** (`docs/incidents/README.md`)
4. **Review in retrospective**

**See**: [Root Cause Analysis Process](docs/processes/ROOT_CAUSE_ANALYSIS.md) for full guide

---

## Blameless Postmortem Process

After incidents, conduct blameless postmortems within 48 hours:

### Principles

- Focus on **what** happened, not **who** did it
- Ask "what" and "how" questions (avoid "why" - it implies blame)
- Refer to people by role, not name
- Assume everyone acted with good intentions
- Goal is learning, not punishment

### Postmortem Template

```markdown
# Incident Postmortem: [INC-XXX]

## Summary
**Date**: [Date]  |  **Severity**: [SEV1-4]  |  **Duration**: [X hours]
**Impact**: [Brief description]

## Timeline
- HH:MM - [Event]
- HH:MM - [Detection]
- HH:MM - [Resolution]

## What Happened
[Factual description - no blame]

## Contributing Factors
1. [System/process factor]
2. [System/process factor]

## What Went Well
- [Positive observation]

## Action Items
| Action | Owner (Role) | Due | Status |
|--------|--------------|-----|--------|
| [Action] | [Role] | [Date] | [ ] |

## Lessons Learned
[Key takeaways]
```

### Severity Classification

| Severity | Impact | Response Time |
|----------|--------|---------------|
| SEV1 | Trading halted, financial loss | Immediate |
| SEV2 | Degraded performance, orders affected | < 1 hour |
| SEV3 | Minor issues, no financial impact | < 4 hours |
| SEV4 | Cosmetic, no user impact | Next sprint |

**Why Blameless**: Psychological safety enables honest communication and faster learning (Google Project Aristotle).

---

## Pre-Trade Validation

All order submissions must pass pre-trade validation:

```python
from execution.pre_trade_validator import PreTradeValidator, Order, create_validator

# Create validator with circuit breaker integration
validator = create_validator(
    circuit_breaker=breaker,
    max_position_pct=0.25,
    max_daily_loss_pct=0.03,
)

# Validate before submitting order
order = Order(symbol="SPY", quantity=100, side="buy", order_type="limit")
result = validator.validate(order)

if not result.approved:
    for check in result.failed_checks:
        print(f"Failed: {check.name} - {check.message}")
    return  # Don't submit order

# Safe to submit
submit_order(order)
```

### Validation Checks

| Check | Description |
|-------|-------------|
| Circuit Breaker | Trading not halted |
| Position Limit | Within 25% max per position |
| Daily Loss | Within 3% daily loss limit |
| Concentration | Total exposure within limit |
| Order Value | Within min/max range |
| Data Freshness | Price data not stale |
| Duplicate Order | Not a duplicate within 1s |
| Liquidity | Sufficient volume |

**See**: [Pre-Trade Validator](execution/pre_trade_validator.py) for implementation

---

## Regression Testing

Regression tests prevent fixed bugs from recurring:

### Test Structure

```text
tests/regression/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ test_historical_bugs.py   # INC-XXX tests
â”œâ”€â”€ test_edge_cases.py        # Edge case coverage
â””â”€â”€ fixtures/
    â””â”€â”€ historical_data/      # Production data samples
```

### Creating Regression Tests

```python
# tests/regression/test_historical_bugs.py

def test_INC001_websocket_reconnection():
    """
    Regression test for INC-001: Silent WebSocket failure.

    Root Cause: Missing error logging for reconnection.
    Fix: Added logging and retry logic.
    RCA: docs/incidents/INC-001.md
    """
    with mock_websocket_failure():
        connector = WebSocketConnector()
        connector.connect()
        assert "reconnection failed" in caplog.text
        assert connector.retry_count > 0
```

### Running Regression Tests

```bash
# Run all regression tests
pytest tests/regression/ -v -m regression

# Run with Monte Carlo stress tests
pytest -v -m "regression or montecarlo"
```

**See**: [Test Documentation](tests/regression/) for all scenarios

---

## Evaluator-Optimizer Feedback Loop

AI agent prompts are improved through iterative evaluation:

```python
from evaluation.feedback_loop import EvaluatorOptimizerLoop, create_feedback_loop

# Create feedback loop for agent improvement
loop = create_feedback_loop(
    evaluator=agent_evaluator,
    max_iterations=5,
    target_score=0.85,
    convergence_threshold=0.02,
)

# Run until convergence
result = loop.run(agent, test_cases)

if result.converged:
    print(f"Improved from {result.initial_aggregate:.2f} to {result.final_aggregate:.2f}")
    print(f"Total improvement: {result.total_improvement:+.3f}")
```

### Feedback Loop Convergence

The loop stops when:

- Target score reached (`target_score`)
- Score changes less than threshold (`convergence_threshold`)
- Maximum iterations reached
- No improvement for N iterations (`no_improvement_patience`)

### Weakness Categories

| Category | Description | Fix Strategy |
|----------|-------------|--------------|
| Accuracy | Low task accuracy | Add specific examples |
| Reasoning | Poor reasoning chain | Add chain-of-thought |
| Consistency | Inconsistent responses | Add format templates |
| Hallucination | Using non-provided data | Add data-only directive |
| Risk Assessment | Missing risk analysis | Add risk checklist |
| Confidence | Miscalibrated confidence | Add calibration examples |

**See**: [Feedback Loop](evaluation/feedback_loop.py) for implementation

---

## Agent Decision Logging

All agent decisions are logged for audit and analysis:

```python
from llm.decision_logger import DecisionLogger, DecisionType, RiskLevel, RiskAssessment

# Create logger
logger = DecisionLogger(auto_persist=True)

# Log a decision
log = logger.log_decision(
    agent_name="technical_analyst",
    agent_role="analyst",
    decision_type=DecisionType.TRADE,
    decision="BUY SPY at 450.00",
    confidence=0.85,
    context={"symbol": "SPY", "price": 450.0, "iv_rank": 0.35},
    query="Analyze SPY for entry opportunity",
    reasoning_chain=[ReasoningStep(1, "Price above 200 SMA", confidence=0.8)],
    risk_assessment=RiskAssessment(
        overall_level=RiskLevel.MEDIUM,
        factors=["market volatility"],
        mitigation_steps=["use stop loss"],
        worst_case_scenario="5% loss",
    ),
)

# Update outcome later
logger.update_outcome(log.log_id, DecisionOutcome.EXECUTED)

# Analyze patterns
analysis = logger.analyze_patterns()
print(f"Average confidence: {analysis.average_confidence:.2f}")
```

### Integration with Agents

Agents automatically log decisions when a logger is configured:

```python
from llm.agents.base import TradingAgent
from llm.decision_logger import DecisionLogger

# Create agent with decision logging
logger = DecisionLogger()
agent = MyTradingAgent(
    name="analyst",
    role=AgentRole.ANALYST,
    system_prompt="...",
    decision_logger=logger,
)
```

**See**: [Decision Logger](llm/decision_logger.py) for implementation

---

## Bull/Bear Debate Mechanism

For major trading decisions, use the multi-agent debate pattern to ensure thorough analysis:

```python
from llm.agents.debate_mechanism import (
    BullBearDebate,
    DebateConfig,
    DebateOutcome,
    DebateTrigger,
)
from llm.agents.bull_researcher import create_bull_researcher
from llm.agents.bear_researcher import create_bear_researcher

# Create debate mechanism
config = DebateConfig(
    max_rounds=3,
    consensus_threshold=0.7,
    min_confidence_delta=0.1,
)

debate = BullBearDebate(
    bull_agent=create_bull_researcher(),
    bear_agent=create_bear_researcher(),
    config=config,
)

# Run structured debate
opportunity = {"symbol": "SPY", "price": 450.0, "has_position": False}
initial_analysis = {"technicals": {"rsi": 55}, "sentiment": {"news_sentiment": 0.2}}

result = debate.run_debate(opportunity, initial_analysis)

# Check outcome
if result.final_outcome == DebateOutcome.BUY:
    print(f"Consensus to BUY with {result.consensus_confidence:.0%} confidence")
elif result.final_outcome == DebateOutcome.HOLD:
    print("No consensus - hold off on trade")

# Review debate rounds
for round in result.rounds:
    print(f"Round {round.round_number}:")
    print(f"  Bull: {round.bull_argument.confidence:.0%} - {round.bull_argument.content[:50]}...")
    print(f"  Bear: {round.bear_argument.confidence:.0%} - {round.bear_argument.content[:50]}...")
```

### When to Trigger Bull/Bear Debate

Use multi-agent debate for major trading decisions when ANY of:

| Condition | Threshold | Reason |
|-----------|-----------|--------|
| Position size | > 10% of portfolio | High-impact trade |
| Initial confidence | < 70% | Uncertain analysis |
| Conflicting signals | Mixed bull/bear indicators | Need tiebreaker |
| High-impact event | Earnings, Fed, major news | Event risk |
| Unusual market | VIX > 25, circuit breakers | Elevated uncertainty |

```python
# Check if debate is warranted
should_debate, trigger = debate.should_debate(
    opportunity={"symbol": "AAPL", "price": 180.0},
    context={"position_size_pct": 0.15, "vix": 28},
    initial_confidence=0.65,
)

if should_debate:
    print(f"Debate triggered due to: {trigger.name}")
    result = debate.run_debate(opportunity, analysis)
```

### Debate Outcomes

| Outcome | Meaning | When Triggered |
|---------|---------|----------------|
| `BUY` | Bullish consensus | Bull confidence > Bear + min_delta, no position |
| `SELL` | Bearish consensus on position | Bear wins, has position |
| `HOLD` | No consensus | Confidence difference < min_delta |
| `AVOID` | Bearish consensus, no position | Bear wins, no position |

**See**: [Debate Mechanism](llm/agents/debate_mechanism.py), [Bull Researcher](llm/agents/bull_researcher.py), [Bear Researcher](llm/agents/bear_researcher.py)

---

## Agent Performance Metrics

Track and analyze agent performance over time:

```python
from evaluation.agent_metrics import (
    AgentMetricsTracker,
    create_metrics_tracker,
    generate_metrics_report,
)

# Create tracker
tracker = create_metrics_tracker(
    max_history=10000,
    evaluation_window_days=30,
)

# Record decisions
tracker.record_decision(
    agent_name="technical_analyst",
    decision_type="analysis",
    decision="BUY",
    confidence=0.85,
    was_correct=True,  # Set later when outcome known
    execution_time_ms=150.0,
    reasoning_steps=4,
)

# Get agent metrics
metrics = tracker.get_metrics("technical_analyst")
print(f"Accuracy: {metrics.accuracy_rate:.1%}")
print(f"Calibration Error: {metrics.calibration_error:.3f}")
print(f"Avg Confidence: {metrics.average_confidence:.1%}")

# Compare agents
comparison = tracker.compare_agents(
    agent_names=["technical_analyst", "sentiment_analyst"],
    metric_name="accuracy",
)
print(f"Best performer: {comparison.best_agent}")

# Generate report
report = generate_metrics_report(tracker)
print(report)
```

### Key Metrics Tracked

| Metric | Description | Good Value |
|--------|-------------|------------|
| `accuracy_rate` | Correct decisions / Total | > 60% |
| `calibration_error` | \|Confidence - Accuracy\| | < 0.1 |
| `overconfidence_rate` | High confidence + Wrong | < 20% |
| `underconfidence_rate` | Low confidence + Right | < 20% |
| `average_execution_time_ms` | Decision latency | < 500ms |

**See**: [Agent Metrics](evaluation/agent_metrics.py) for implementation

---

## Self-Evolving Agents

Agents that automatically improve through evaluation-refinement cycles (UPGRADE-005):

```python
from llm import (
    SelfEvolvingAgent,
    PromptOptimizer,
    create_self_evolving_agent,
    create_prompt_optimizer,
    generate_evolution_report,
)
from llm.agents import create_technical_analyst

# Create base agent
base_agent = create_technical_analyst(llm_client)

# Wrap with self-evolving capabilities
evolving_agent = create_self_evolving_agent(
    base_agent=base_agent,
    target_score=0.85,      # Target performance score
    max_cycles=5,           # Maximum evolution cycles
    improvement_threshold=0.02,  # Minimum improvement per cycle
)

# Run evolution with test scenarios
test_cases = [
    {"query": "Analyze SPY technicals", "context": {"price": 450.0}},
    {"query": "Should we buy AAPL?", "context": {"rsi": 30, "trend": "up"}},
]

result = evolving_agent.evolve(test_scenarios=test_cases)

# Check results
if result.converged:
    print(f"Evolution successful!")
    print(f"Initial score: {result.initial_score:.1%}")
    print(f"Final score: {result.final_score:.1%}")
    print(f"Improvement: {result.total_improvement:+.1%}")
    print(f"Cycles completed: {len(result.cycles)}")
else:
    print(f"Evolution stopped: {result.convergence_reason.value}")

# Get the evolved agent
improved_agent = evolving_agent.get_evolved_agent()

# Generate detailed report
report = generate_evolution_report(result)
print(report)
```

### Self-Evolution Triggers

Self-evolution runs when ANY of:

| Trigger | Condition | Action |
|---------|-----------|--------|
| Scheduled evaluation | Weekly score drop > 5% | Auto-trigger evolution |
| Manual trigger | User request | Run evolution cycle |
| Market regime change | Volatility shift detected | Adapt prompts |
| New scenarios added | After adding test cases | Validate against new cases |

### Prompt Optimizer

Automatic prompt refinement based on identified weaknesses:

```python
from llm import PromptOptimizer, create_prompt_optimizer

# Create optimizer
optimizer = create_prompt_optimizer(
    strategy="rule_based",  # or "llm_assisted", "hybrid"
    max_refinements=5,
    min_impact=0.05,
)

# Analyze prompt for improvements
current_prompt = "You are a trading analyst."
analysis = optimizer.analyze_prompt(current_prompt)

print(f"Potential weaknesses: {analysis['potential_weaknesses']}")
print(f"Improvement potential: {analysis['improvement_potential']:.1%}")

# Generate refinements based on weaknesses
weaknesses = ["Missing concrete examples", "Missing step-by-step process"]
refinements = optimizer.generate_refinements(current_prompt, weaknesses)

for ref in refinements:
    print(f"- {ref.category.value}: {ref.description}")
    print(f"  Expected impact: {ref.expected_impact:.1%}")

# Apply refinements
new_prompt = optimizer.apply_refinements(current_prompt, refinements)
```

### Refinement Categories

| Category | Description | Example |
|----------|-------------|---------|
| `add_examples` | Add concrete examples | "When analyzing SPY, evaluate technicals..." |
| `improve_structure` | Add step-by-step process | "1. Gather data 2. Analyze signals..." |
| `add_constraints` | Add explicit constraints | "Max 2% risk per trade..." |
| `add_error_handling` | Add error handling guidance | "On uncertainty, recommend HOLD..." |
| `clarify_instructions` | Clarify ambiguous language | "should consider" â†’ "must evaluate" |
| `remove_conflicts` | Resolve conflicting guidance | Balance competing objectives |

### Convergence Reasons

| Reason | Meaning | Next Steps |
|--------|---------|------------|
| `TARGET_REACHED` | Target score achieved | Deploy evolved agent |
| `NO_IMPROVEMENT` | Improvement below threshold | Consider different approach |
| `MAX_CYCLES_REACHED` | Hit cycle limit | May need more cycles |
| `REGRESSION_DETECTED` | Score decreased | Rollback to best version |

**See**: [Self-Evolving Agent](llm/self_evolving_agent.py), [Prompt Optimizer](llm/prompt_optimizer.py)

---

## Slippage Monitoring

Track execution slippage in real-time:

```python
from execution.slippage_monitor import SlippageMonitor, create_slippage_monitor

# Create monitor with alert thresholds
monitor = create_slippage_monitor(
    alert_threshold_bps=10.0,   # Warning at 10 bps
    critical_threshold_bps=25.0, # Critical at 25 bps
)

# Record fills
record = monitor.record_fill(
    order_id="ORD001",
    symbol="SPY",
    expected_price=450.00,
    actual_price=450.05,
    quantity=100,
    side="buy",
)

print(f"Slippage: {record.slippage_bps:.2f} bps ({record.direction.value})")

# Get metrics
metrics = monitor.get_metrics()
print(f"Average slippage: {metrics.avg_slippage_bps:.2f} bps")
print(f"Total slippage cost: ${metrics.total_slippage_value:.2f}")
```

### Slippage Direction

| Side | Price Higher | Price Lower |
|------|--------------|-------------|
| Buy | Adverse (paid more) | Favorable (paid less) |
| Sell | Favorable (received more) | Adverse (received less) |

**See**: [Slippage Monitor](execution/slippage_monitor.py) for implementation

---

## Execution Quality Metrics

Monitor overall execution quality:

```python
from execution.execution_quality_metrics import (
    ExecutionQualityTracker,
    OrderStatus,
    create_execution_tracker,
)

# Create tracker
tracker = create_execution_tracker()

# Record orders
tracker.record_order(
    order_id="ORD001",
    symbol="SPY",
    quantity=100,
    filled_quantity=100,
    side="buy",
    order_type="limit",
    status=OrderStatus.FILLED,
    submit_time=submit_time,
    fill_time=fill_time,
    latency_ms=45.0,
    expected_price=450.00,
    fill_price=450.05,
)

# Get dashboard
dashboard = tracker.get_dashboard()
print(f"Fill Rate: {dashboard.fill_rate_pct:.1f}%")
print(f"Quality Score: {dashboard.quality_score:.1f}/100")
```

### Quality Metrics Dashboard

| Metric | Target | Status |
|--------|--------|--------|
| Fill Rate | > 80% | fill_rate_status |
| Avg Slippage | < 5 bps | slippage_status |
| Avg Latency | < 100ms | latency_status |
| Cancel Rate | < 10% | cancel_rate_status |

### Quality Score

Composite score (0-100) based on:

- Fill rate (40%)
- Slippage (25%)
- Latency (20%)
- Cancel rate (15%)

**See**: [Execution Quality Metrics](execution/execution_quality_metrics.py) for implementation

---

## Docker Containerization

### Build and Run

```bash
# Build the sandbox image
docker build -t trading-sandbox .

# Run with security restrictions (development)
docker run -it \
    --cap-drop ALL \
    --memory=2g \
    --cpus=2 \
    --network=none \
    --read-only \
    --tmpfs /tmp \
    -v $(pwd)/algorithms:/app/algorithms:rw \
    trading-sandbox

# Use docker-compose for predefined environments
docker-compose run sandbox    # Development
docker-compose run backtest   # Backtesting
docker-compose run analysis   # Results analysis
```

### DevContainer (VS Code)

Open in VS Code with Remote Containers extension for automatic setup:
- Pre-configured Python environment
- All extensions installed
- Security restrictions applied

## MCP Configuration

The `.mcp.json` file configures Model Context Protocol for Claude Code:

```json
{
  "mcpServers": {
    "filesystem": {...},
    "git": {...}
  },
  "settings": {
    "autoApprove": {
      "read": true,
      "write": ["algorithms/**", "tests/**"],
      "execute": ["pytest", "lean backtest"]
    }
  }
}
```

## GitHub Actions with Claude Code

Tag `@claude` in PR comments to:
- Analyze code changes
- Suggest improvements
- Fix failing CI
- Deep strategy analysis (use `@claude analyze`)

Workflow: `.github/workflows/claude-code-review.yml`

## Options Trading Patterns

### Initialize Options with Greeks

```python
def initialize(self):
    equity = self.add_equity("SPY")
    option = self.add_option("SPY")
    option.set_filter(-10, +10, 0, 90)  # Â±10 strikes, 0-90 days

    # Optional: Specify pricing model (defaults to Black-Scholes/Bjerksund-Stensland)
    # option.price_model = OptionPriceModels.crank_nicolson_fd()

    # NOTE: As of LEAN PR #6720, Greeks use IV and require NO warmup
    # Greeks are available immediately upon option data arrival
```

### Access Greeks in OnData

```python
def on_data(self, slice):
    chain = slice.option_chains.get(self.option_symbol)
    if not chain:
        return

    # Greeks available immediately (IV-based, no warmup required)
    for contract in chain:
        delta = contract.greeks.delta
        gamma = contract.greeks.gamma
        theta = contract.greeks.theta
        theta_per_day = contract.greeks.theta_per_day  # Daily theta decay
        vega = contract.greeks.vega
        rho = contract.greeks.rho
        iv = contract.implied_volatility

        # Greeks values match Interactive Brokers and major brokerages
        if 0.25 < abs(delta) < 0.35 and iv > 0.20:
            self.market_order(contract.symbol, 1)
```

### Strategy Filters

```python
# Iron condor filter
option.set_filter(lambda u: u.iron_condor(30, 5, 10))

# Straddle filter
option.set_filter(lambda u: u.straddle(30))
```

### Greeks-Based Universe Filtering

**Recommended**: Filter options using Greeks **before** they enter your scanner to reduce data processing:

```python
def initialize(self):
    option = self.add_option("SPY")
    option.set_filter(self.option_filter)

def option_filter(self, universe):
    """Filter options by Greeks and IV before detailed analysis"""
    return (universe
        .delta(0.25, 0.35)               # Delta range for scanner
        .implied_volatility(0.20, None)  # Minimum IV threshold
        .expiration(30, 180)             # DTE range
        .strikes(-10, 10)                # Strike range from ATM
        .include_weeklys())              # Include weekly options
```

**Available Chainable Filter Methods:**

- `.delta(min, max)` or `.d(min, max)` - Filter by delta
- `.gamma(min, max)` or `.g(min, max)` - Filter by gamma
- `.vega(min, max)` or `.v(min, max)` - Filter by vega
- `.theta(min, max)` or `.t(min, max)` - Filter by theta
- `.rho(min, max)` or `.r(min, max)` - Filter by rho
- `.implied_volatility(min, max)` or `.iv(min, max)` - Filter by IV
- `.open_interest(min, max)` or `.oi(min, max)` - Filter by open interest

**Benefits:**

- Reduces data to process in scanners
- Faster backtests and live execution
- Lower memory usage with large option chains

### OptionStrategies Factory Methods

**QuantConnect provides 37+ pre-built strategy constructors** that automatically create multi-leg positions with proper grouping and margin calculation.

**Pattern - Butterfly Call:**

```python
def on_data(self, slice):
    chain = slice.option_chains.get(self.option_symbol)
    if not chain:
        return

    # Get strikes
    expiry = min([x.expiry for x in chain])
    strikes = sorted([c.strike for c in chain if c.expiry == expiry])

    # Use factory method instead of manual Leg.Create()
    strategy = OptionStrategies.butterfly_call(
        self.option_symbol,
        strikes[0],   # Lower strike (buy)
        strikes[2],   # Middle strike (sell 2x)
        strikes[4],   # Upper strike (buy)
        expiry
    )

    # Buy or sell the entire strategy atomically
    self.buy(strategy, 1)      # Long butterfly
    # OR
    self.sell(strategy, 1)     # Short butterfly
```

**Pattern - Iron Condor:**

```python
strategy = OptionStrategies.iron_condor(
    self.option_symbol,
    put_buy_strike,    # Lower put protection
    put_sell_strike,   # Put income
    call_sell_strike,  # Call income
    call_buy_strike,   # Upper call protection
    expiry
)
self.buy(strategy, 1)  # Execute entire condor atomically
```

**Common Strategy Factory Methods:**

| Strategy Type | Method | Legs |
|---------------|--------|------|
| Butterfly Call | `OptionStrategies.butterfly_call()` | Buy 1, Sell 2, Buy 1 |
| Butterfly Put | `OptionStrategies.butterfly_put()` | Buy 1, Sell 2, Buy 1 |
| Iron Butterfly | `OptionStrategies.iron_butterfly()` | Buy put, Sell put+call, Buy call |
| Iron Condor | `OptionStrategies.iron_condor()` | Buy put, Sell put, Sell call, Buy call |
| Bull Call Spread | `OptionStrategies.bull_call_spread()` | Buy lower, Sell upper |
| Bear Put Spread | `OptionStrategies.bear_put_spread()` | Buy upper, Sell lower |
| Straddle | `OptionStrategies.straddle()` | Buy call + put at same strike |
| Strangle | `OptionStrategies.strangle()` | Buy OTM call + OTM put |
| Covered Call | `OptionStrategies.covered_call()` | Long stock + sell call |

**37+ strategies available** - see [OptionStrategies.cs](https://github.com/QuantConnect/Lean/blob/master/Common/Securities/Option/OptionStrategies.cs) for complete list.

**Benefits of Factory Methods:**
- Automatic position grouping for correct margin calculations
- Cleaner code (no manual `Leg.Create()` calls)
- Automatic strategy detection by LEAN
- Compatible with `ComboLimitOrder()` execution
- Single command to enter/exit entire position

**Note:** You can still use manual `Leg.Create()` with `ComboLimitOrder()` for custom strategies or precise price control.

## Configuration System

All trading parameters are configurable via `config/settings.json`:

```python
from config import get_config, ConfigManager

config = get_config()

# Access nested values
max_daily_loss = config.get("risk_management.max_daily_loss_pct")

# Get typed config objects
profit_config = config.get_profit_taking_config()
for threshold in profit_config.thresholds:
    print(f"Sell {threshold.sell_pct:.0%} at +{threshold.gain_pct:.0%}")

# Update values
config.update("movement_scanner.min_movement_pct", 0.03)
config.save()
```

### Key Configuration Sections

| Section | Description |
|---------|-------------|
| `brokerage` | Schwab API credentials and settings |
| `risk_management` | Position limits, daily loss, drawdown |
| `profit_taking` | Threshold levels for selling winners |
| `order_execution` | Cancel/replace settings |
| `options_scanner` | Delta range, DTE, IV thresholds |
| `movement_scanner` | Movement %, volume surge |
| `llm_integration` | Provider configs, ensemble weights |
| `technical_indicators` | Indicator parameters |
| `ui` | Dashboard theme and layout |

## Running the Dashboard

```python
from ui import create_dashboard, run_dashboard

# Create dashboard with config
dashboard = create_dashboard(config=config.get("ui"))

# Connect callbacks
def on_sell(symbol, quantity, order_type):
    # Execute sell order
    pass

dashboard.on_sell = on_sell

# Run the application
run_dashboard(dashboard)
```

## LLM Dashboard (UPGRADE-006 - December 2025)

The trading dashboard includes integrated LLM agent analytics panels:

### LLM Dashboard Widgets

| Widget | Purpose | Access |
|--------|---------|--------|
| **Agent Metrics** | Real-time performance metrics (accuracy, calibration, confidence) | View â†’ LLM Dashboard â†’ Agent Metrics |
| **Debate Viewer** | Visualize Bull/Bear debate sessions with round navigation | View â†’ LLM Dashboard â†’ Debate Viewer |
| **Evolution Monitor** | Track self-evolving agent progress and prompt versions | View â†’ LLM Dashboard â†’ Evolution Monitor |
| **Decision Log** | Browse and filter agent decision history | View â†’ LLM Dashboard â†’ Decision Log |

### Quick Start: LLM Dashboard

```python
from ui import create_llm_dashboard, run_dashboard
from evaluation.agent_metrics import AgentMetricsTracker
from llm.agents.debate_mechanism import BullBearDebate
from llm.decision_logger import DecisionLogger

# Create trackers
tracker = AgentMetricsTracker()
debate = BullBearDebate()
logger = DecisionLogger()

# Create dashboard with LLM panels pre-configured
dashboard = create_llm_dashboard(
    metrics_tracker=tracker,
    debate_mechanism=debate,
    decision_logger=logger,
)

# Run the application
run_dashboard(dashboard)
```

### Adding LLM Widgets to Existing Dashboard

```python
from ui import TradingDashboard

# Create dashboard
dashboard = TradingDashboard()

# Configure LLM components
dashboard.set_llm_components(
    metrics_tracker=tracker,
    debate_mechanism=debate,
    evolving_agents=[agent1, agent2],
    decision_logger=logger,
)

# Show LLM panels via menu or programmatically
dashboard._show_all_llm_docks()
```

### Individual Widget Usage

**Agent Metrics Widget:**

```python
from ui import create_agent_metrics_widget
from evaluation.agent_metrics import AgentMetricsTracker

tracker = AgentMetricsTracker()
widget = create_agent_metrics_widget(metrics_tracker=tracker)

# Record decisions
tracker.record_decision(
    agent_name="technical_analyst",
    decision_type="trade",
    decision="BUY",
    confidence=0.85,
)
```

**Debate Viewer Widget:**

```python
from ui import create_debate_viewer

viewer = create_debate_viewer(debate_mechanism=debate)

# Add debate results
result = debate.run_debate(opportunity, context)
viewer.add_debate(result.to_dict())
```

**Evolution Monitor Widget:**

```python
from ui import create_evolution_monitor

monitor = create_evolution_monitor(evolving_agents=[agent1, agent2])

# Add evolution results
result = evolving_agent.evolve(test_cases)
monitor.add_evolution_result("technical_analyst", result.to_dict())
```

**Decision Log Viewer Widget:**

```python
from ui import create_decision_log_viewer
from llm.decision_logger import DecisionLogger

logger = DecisionLogger()
viewer = create_decision_log_viewer(decision_logger=logger)

# Logs are automatically displayed when added to logger
```

## Using the LLM Ensemble

```python
from llm import create_ensemble, create_news_analyzer

# Create ensemble with multiple providers
ensemble = create_ensemble(config.get_llm_config())

# Analyze sentiment
result = ensemble.analyze_sentiment("Apple reports record earnings...")
print(f"Sentiment: {result.sentiment.signal.name}")
print(f"Confidence: {result.sentiment.confidence:.2f}")
print(f"Agreement: {result.agreement_score:.2f}")

# Analyze news
news_analyzer = create_news_analyzer(config.get("news_alerts"))
alerts = news_analyzer.analyze_news()
for alert in alerts:
    print(f"{alert.symbol}: {alert.headline} ({alert.urgency})")
```

## Using the Scanners

```python
from scanners import create_options_scanner, create_movement_scanner

# Options scanner
options_scanner = create_options_scanner(config.get_options_scanner_config())
opportunities = options_scanner.scan_chain(
    underlying="AAPL",
    spot_price=175.50,
    chain=option_contracts,
)
for opp in opportunities:
    print(f"{opp.contract.symbol}: {opp.underpriced_pct:.1%} underpriced")

# Movement scanner
movement_scanner = create_movement_scanner(config.get_movement_scanner_config())
alerts = movement_scanner.scan(price_data)
for alert in alerts:
    print(f"{alert.symbol}: {alert.movement_pct:+.1%} ({alert.urgency})")
```

## Strategy Documentation (IMPORTANT)

### Auto-Update Policy

**CRITICAL: When the user provides ANY information about their trading strategies, Claude MUST:**

1. **Update the relevant strategy README** in `docs/strategies/`
2. **Add to this section** if it's core strategy insight
3. **Update changelog** in affected documentation files

### Strategy Documentation Files

| File | Purpose |
|------|---------|
| `docs/strategies/README.md` | Strategy index and overview |
| `docs/strategies/TWO_PART_SPREAD_STRATEGY.md` | Primary trading strategy |
| `docs/strategies/ARBITRAGE_EXECUTOR.md` | Execution system details |

### When User Mentions Strategy Details

If user provides information about:
- Fill rates or timing â†’ Update `TWO_PART_SPREAD_STRATEGY.md` "Key Observations" section
- Parameter values â†’ Update "Configuration Parameters" sections
- New trading rules â†’ Update "Trading Rules" section
- Performance data â†’ Update "Success Metrics" section
- New features â†’ Update "Implementation Guide" and relevant module docs

### Example Update Triggers

| User Says | Update |
|-----------|--------|
| "I noticed fills work better at X time" | Add to "Key Observations from Live Trading" |
| "The delay should be Y seconds" | Update "Timing Parameters" table |
| "My fill rate is about Z%" | Update "Success Metrics" section |
| "I want to add feature W" | Add to implementation guide and create module |

---

## Research Documentation (IMPORTANT)

### Auto-Documentation Policy

**CRITICAL: When Claude conducts ANY online research, it MUST:**

1. **Create a research document** in `docs/research/` with detailed findings
2. **Update the research index** (`docs/research/README.md`)
3. **Update CLAUDE.md** with new patterns/instructions if applicable
4. **Create implementation examples** if code was written

### Automated Documentation Enforcement

The project includes hooks and scripts that automatically enforce documentation standards:

**Hooks (in `.claude/settings.json`):**

| Hook | Trigger | Purpose |
|------|---------|---------|
| `validation/validate_research.py` | PostToolUse (Edit/Write) | Validates research doc naming and frontmatter |
| `research/document_research.py` | PostToolUse (WebSearch/WebFetch) | Reminds to document after 3+ web searches |
| `core/ric.py` | PreToolUse + UserPromptSubmit | RIC v5.1 Guardian enforcement |
| `validation/validate_category_docs.py` | PostToolUse (Edit/Write) | Validates category docs exist for multi-category upgrades |

**Scripts:**

| Script | Command | Purpose |
|--------|---------|---------|
| `research_saver.py` | `python3 .claude/hooks/research/research_saver.py create --type upgrade --name "Title"` | **Recommended** - Intelligent document creation with templates |
| `create_research_doc.py` | `python scripts/create_research_doc.py "Title" --topic X` | Create new research doc with template |
| `create_category_doc.py` | `python scripts/create_category_doc.py UPGRADE-014 3 "Fault Tolerance"` | Create category research doc |
| `validate_research_docs.py` | `python scripts/validate_research_docs.py` | Full validation of all docs |
| `update_research_index.py` | `python scripts/update_research_index.py` | Update cross-references |

**Slash Commands:**

| Command | Purpose |
|---------|---------|
| `/save-research <type> "Title"` | **Recommended** - Create documents with proper naming and templates |
| `/validate-docs` | Run documentation validation |
| `/ric-research` | Start Phase 0 research with documentation protocol |
| `/ric-converge` | Convergence check including doc validation |

**Document Types (for `/save-research`):**

| Type | Pattern | Location | Use Case |
|------|---------|----------|----------|
| `upgrade` | `UPGRADE-NNN-NAME.md` | `docs/research/` | Implementation checklists with phases and tasks |
| `research` | `NAME-RESEARCH.md` | `docs/research/` | Research findings with sources and discoveries |
| `category` | `UPGRADE-NNN-CATN-NAME-RESEARCH.md` | `docs/research/` | Category-specific research for upgrades |
| `insight` | `INSIGHT-YYYY-MM-DD-NAME.md` | `docs/insights/` | Quick insights with evidence and application |
| `guide` | `NAME-GUIDE.md` | `docs/guides/` | How-to guides with examples and troubleshooting |

**Templates Location:** `.claude/templates/` contains advanced templates for each document type.

**Integration with RIC Loop:**

1. **Phase 0 (Research)**: `/ric-research` command includes documentation steps
2. **Phase 4 (Reflect)**: `/ric-converge` includes mandatory doc validation before exit
3. **Automatic reminders**: After 3+ web searches without documentation, hook reminds to document

### Research Documentation Files

| File | Purpose |
|------|---------|
| `docs/research/README.md` | Research index and overview |
| `docs/research/EVALUATION_FRAMEWORK_RESEARCH.md` | Evaluation frameworks research (Dec 2025) |
| `docs/research/PHASE3_ADVANCED_FEATURES_RESEARCH.md` | QuantConnect advanced features (Nov 2025) |
| `docs/research/PHASE_2_INTEGRATION_RESEARCH.md` | QuantConnect integration research (Nov 2025) |

### When Claude Conducts Research

If Claude searches online for:

- **New evaluation methodology** â†’ Create/update research document in `docs/research/`
- **QuantConnect features** â†’ Update appropriate PHASE research document
- **Trading strategies** â†’ Document in `docs/research/` and `docs/strategies/`
- **AI agent patterns** â†’ Create research document and update `CLAUDE.md`
- **Best practices** â†’ Document findings and update relevant docs

### Research Documentation Process

1. **Create Research Document**:
   - Filename: `[TOPIC]_RESEARCH.md` in `docs/research/`
   - Include: Search date/time, search queries, sources (URLs with publication dates), key findings, impact
   - Use template from `docs/research/README.md`
   - **CRITICAL**: Timestamp all searches and sources (see timestamping requirements below)

2. **Update Research Index**:
   - Add new research phase to `docs/research/README.md`
   - Update deliverables table
   - Add critical discoveries
   - Update implementation status
   - Add change log entry with date

3. **Update CLAUDE.md** (if needed):
   - Add new patterns to relevant sections
   - Update command reference
   - Add example usage

4. **Create Examples** (if code written):
   - Working integration examples
   - Usage patterns
   - Best practices

### Thorough Research with Fast Agents (NEW)

For comprehensive research, use multi-pass URL fetching with parallel haiku agents:

**Quick Command**:

```bash
/thorough-research <url_or_topic>
```

**CLI Helper**:

```bash
# Generate parallel Task calls for multiple URLs
python3 .claude/hooks/research/thorough_research.py plan <url1> <url2> --topic "Topic"

# Quick overview only (faster)
python3 .claude/hooks/research/thorough_research.py generate <url> --quick

# Show available fetch prompts
python3 .claude/hooks/research/thorough_research.py prompts
```

**How It Works**:

1. **WebSearch** finds relevant URLs
2. **Haiku agents spawn in parallel** (4 per URL):
   - Overview & Concepts
   - Code Examples (verbatim)
   - API & Configuration
   - Usage Patterns
3. **Results consolidated** and saved to `docs/research/` immediately

**Multi-Pass Extraction Prompts**:

| Category | What's Extracted |
|----------|------------------|
| `overview` | Main concepts, architecture, terminology |
| `code` | ALL code examples verbatim with formatting |
| `api` | Function signatures, endpoints, parameters |
| `config` | Settings, environment variables, defaults |
| `examples` | Usage patterns, best practices |
| `troubleshooting` | Errors, FAQs, solutions |

**Benefits**:

- 4x more information captured per URL
- Parallel execution (~30-60 seconds total)
- Haiku model = fast and cost-effective
- Immediate persistence prevents context compaction loss

**Integration with RIC Loop**:

Phase 0 (Research) now recommends thorough fetching:

```text
[I1/5][P0] RESEARCH â†’ Use /thorough-research for important URLs
```

### Multi-Category Upgrade Documentation (CRITICAL)

**For upgrades with multiple categories** (like UPGRADE-014 with 12 categories), additional documentation requirements apply:

#### Naming Convention

```text
UPGRADE-014-AUTONOMOUS-AGENT-ENHANCEMENTS.md      # Main document (overview)
UPGRADE-014-CAT1-ARCHITECTURE-RESEARCH.md         # Category 1 research
UPGRADE-014-CAT2-OBSERVABILITY-RESEARCH.md        # Category 2 research
UPGRADE-014-CAT3-FAULT-TOLERANCE-RESEARCH.md      # Category 3 research
...
```

**Pattern**: `UPGRADE-NNN-CATN-[CATEGORY-NAME]-RESEARCH.md`

#### Enforcement Rules

1. **BEFORE marking a category COMPLETE** in `claude-progress.txt`:
   - The corresponding research document MUST exist
   - Example: Before `[x] Category 3: Fault Tolerance`, ensure `UPGRADE-014-CAT3-FAULT-TOLERANCE-RESEARCH.md` exists

2. **During implementation**:
   - Create the category research doc FIRST using the template
   - Document discoveries as you implement
   - Link to implementation files in the research doc

3. **For autonomous sessions**:
   - The `validate_category_docs.py` hook validates completeness
   - Missing docs will generate warnings
   - Session stop hook checks documentation status

#### Creating Category Documents

```bash
# Use the generator script
python scripts/create_category_doc.py UPGRADE-014 3 "Fault Tolerance"
# Creates: docs/research/UPGRADE-014-CAT3-FAULT-TOLERANCE-RESEARCH.md

# Or use template at docs/research/templates/category_research_template.md
```

#### Category Documentation Validation

```bash
# Validate all category documentation exists
python .claude/hooks/validation/validate_category_docs.py
```

### Timestamping Requirements (CRITICAL)

**All research MUST include two types of timestamps:**

1. **Search Timestamp**: When the search was conducted
   - Format: `**Search Date**: December 1, 2025 at 10:30 AM EST`
   - Include in each research phase

2. **Source Publication Date**: When the source was published
   - Format: `[Source Title (Published: Oct 2024)](URL)`
   - Estimate if exact date unknown: `(Published: ~2025)`, `(Published: 2024-2025)`
   - Mark as unknown if cannot determine: `(Published: Unknown)`

### Compaction Protection (CRITICAL)

**IMMEDIATELY persist research findings to files to avoid loss during context compaction:**

1. **After EVERY web search**: Add findings to research document file within same response
2. **Before moving to next phase**: Ensure all research is written to `docs/research/` file
3. **Never hold research in context only**: Context can be compacted at any time, losing findings

**Why This Matters**:
- Context compaction occurs when conversation reaches ~70% of 200K tokens
- Research held only in conversation context will be summarized/lost
- Persisted files survive compaction and are available for future sessions

**Pattern**:
```text
1. WebSearch â†’ Get results
2. IMMEDIATELY Write findings to docs/research/UPGRADE-XXX.md
3. Continue to next search
4. Repeat until all research complete
```

### Why Timestamping Matters:

- Differentiates current working code from outdated patterns
- Identifies deprecated features vs new features
- Validates research against latest best practices
- Helps future Claude sessions assess source reliability

**Examples**:

```markdown
### Phase 1: QuantConnect Greeks Research

**Search Date**: November 30, 2025 at 2:15 PM EST
**Search Query**: "QuantConnect Greeks calculation 2025"

**Key Sources**:
1. [LEAN PR #6720 - IV-Based Greeks (Published: Aug 2024)](https://github.com/QuantConnect/Lean/pull/6720)
2. [QuantConnect Greeks Documentation (Updated: Nov 2025)](https://www.quantconnect.com/docs/greeks)
3. [Community Forum Discussion (Published: ~2024)](https://forum.quantconnect.com/discussion/greeks)
```

### Research Document Template

Use this structure for all research documents:

```markdown
# [Topic] Research - [Month Year]

## ğŸ“‹ Research Overview

**Date**: [Date when research was conducted]
**Scope**: [What was researched]
**Focus**: [Specific areas]
**Result**: [Summary of deliverables]

## ğŸ¯ Research Objectives

1. [Objective 1]
2. [Objective 2]

## ğŸ“Š Research Phases

### Phase 1: [Name]

**Search Date**: [Date and time of search, e.g., "December 1, 2025 at 10:30 AM EST"]
**Search Queries**: [List exact queries used]

**Key Sources**:

1. [Source Title (Published: Month Year)](URL)
2. [Source Title (Updated: Month Year)](URL)
3. [Source Title (Published: ~Year)](URL) - if estimate

**Key Discoveries**:

- [Finding 1]
- [Finding 2]

**Applied**: [What was implemented]

### Phase 2: [Name]

**Search Date**: [Date and time]
**Search Queries**: [Queries]

**Key Sources**:

1. [Source (Published: Date)](URL)

**Key Discoveries**: [Findings]
**Applied**: [Implementation]

## ğŸ”‘ Critical Discoveries

[Most important findings with impact assessment and source publication dates]

## ğŸ’¾ Research Deliverables

[Files created, lines of code, documentation size]

## ğŸ“ Change Log

| Date | Change | Impact |
|------|--------|--------|
| YYYY-MM-DD | [Change description] | [Impact] |
```

### Research Update Triggers

| Claude Action | Required Documentation |
|--------------|------------------------|
| Searches "autonomous AI evaluation 2025" | Create `EVALUATION_FRAMEWORK_RESEARCH.md`, update index |
| Discovers new QuantConnect feature | Update `PHASE3_ADVANCED_FEATURES_RESEARCH.md` |
| Finds new trading metric | Update research doc, add to `advanced_trading_metrics.py` |
| Researches prompt engineering | Document findings, update agent prompts |

**Why This Matters**: Research without documentation is lost. Future Claude sessions (and humans) need to understand what was discovered, why decisions were made, and where to find the sources.

---

## Core Trading Strategy Reference

### Two-Part Spread Strategy (Primary)

**Philosophy**: Leg into butterflies/iron condors in two parts to achieve net-credit positions.

**Key Insight**: Wide bid-ask spreads are OPPORTUNITIES (can get filled below mid), not risks to avoid.

**Process**:
1. Find underpriced debit spread (wide spreads = opportunity)
2. Execute debit at 35% from bid with 2.5s quick cancel
3. Find credit spread further OTM with credit >= debit cost
4. Execute credit at 65% from bid to complete position

**Critical Parameters**:
- Cancel unfilled orders after: **2.5 seconds**
- Minimum delay between attempts: **3 seconds**
- Maximum delay between attempts: **15 seconds**
- Minimum fill rate threshold: **25%**
- Starting contract size: **1 contract** (highest fill probability)
- Optimal expiration range: **30-180 days**

**User Observations (from live trading)**:
- Orders that don't fill in 2-3 seconds won't fill at all
- 1 contract at a time offers highest fill rate but low volume
- Random delays prevent market maker algorithm detection
- Wide spreads mean price improvement opportunity, not risk
- Position balance per option chain prevents holding excess longs

**Implementation Files**:
- `execution/two_part_spread.py` - Core strategy logic
- `execution/arbitrage_executor.py` - Full autonomous executor
- `execution/fill_predictor.py` - Fill rate tracking
- `execution/spread_analysis.py` - Spread quality analysis
- `models/enhanced_volatility.py` - IV analysis for opportunities

---

## Agent Personas (UPGRADE-015)

Specialized agent personas are available in `.claude/agents/` for different development tasks. Use these with the Task tool for focused expertise.

### Available Personas

| Persona | File | Use Case |
|---------|------|----------|
| **Senior Engineer** | `senior-engineer.md` | Complex implementation, architecture, code quality |
| **Risk Reviewer** | `risk-reviewer.md` | Trading safety review, risk validation, compliance |
| **Strategy Dev** | `strategy-dev.md` | Strategy design, options expertise, backtest analysis |
| **Code Reviewer** | `code-reviewer.md` | PR reviews, security audit, code quality checks |
| **QA Engineer** | `qa-engineer.md` | Test design, coverage analysis, quality gates |
| **Researcher** | `researcher.md` | Technical research, market analysis, documentation |
| **Backtest Analyst** | `backtest-analyst.md` | Performance analysis, overfitting detection |

### Usage Examples

```bash
# Use senior engineer for complex implementation
# In Claude Code, invoke via Task tool with appropriate prompt

# Code review before PR
# Use code-reviewer persona for security and quality checks

# Risk assessment for trading changes
# Use risk-reviewer persona for safety validation
```

### Persona Selection Guide

| Task Type | Recommended Persona |
|-----------|---------------------|
| New feature implementation | senior-engineer |
| Trading code changes | risk-reviewer â†’ senior-engineer |
| Strategy development | strategy-dev |
| Pre-commit review | code-reviewer |
| Test creation | qa-engineer |
| Technical research | researcher |
| Backtest evaluation | backtest-analyst |

---

## Multi-Agent Orchestration Suite

A comprehensive system for spawning, coordinating, and managing multiple Claude agents with intelligent model selection and autonomous capabilities.

### Quick Start Commands

| Command | Description | Agents |
|---------|-------------|--------|
| `/agents auto <task>` | **Intelligent auto-routing** - analyzes task and selects best agents | Auto |
| `/agent-quick <task>` | Single fast agent dispatch | 1 |
| `/agent-swarm <topic>` | Massive parallel exploration | 8 |
| `/agent-consensus <decision>` | Multi-agent voting/decision | 3 |
| `/agent-implement <feature>` | Full implementation pipeline | 4 |
| `/agent-compare <options>` | Compare approaches | 2-3 |

### Model Selection Guide

| Model | Speed | Cost | Best For |
|-------|-------|------|----------|
| **haiku** | Fastest | Lowest | File search, grep, simple checks, quick tasks |
| **sonnet** | Medium | Medium | Code review, implementation, balanced analysis |
| **opus** | Slowest | Highest | Architecture design, deep reasoning, critical decisions |

### Intelligent Auto-Selection

The `/agents auto` command automatically analyzes tasks and selects optimal agents:

```bash
/agents auto find all error handling code          # â†’ 3 haiku search agents
/agents auto review the execution module           # â†’ 4 review agents (haiku+sonnet)
/agents auto design caching strategy               # â†’ 2 agents (haiku research + sonnet design)
/agents auto should we refactor authentication     # â†’ 3 consensus agents (sonnet)
```

**Auto-Classification:**

| Task Pattern | Classification | Model | Agent Count |
|--------------|----------------|-------|-------------|
| find, search, where | SEARCH | haiku | 3 |
| review, check, audit | REVIEW | haiku+sonnet | 4 |
| implement, create, build | BUILD | sonnet | 2-4 |
| design, architect, plan | DESIGN | sonnet | 2 |
| trading, risk, execution | TRADING | sonnet | 3 |
| decide, should, choose | CONSENSUS | sonnet | 3 |

### Pre-Built Workflows

| Workflow | Pattern | Agents | Use Case |
|----------|---------|--------|----------|
| `code_review` | Parallel | 4 | Security + Types + Tests + Architecture |
| `multi_search` | Parallel | 3 | Code + Docs + Tests search |
| `trading_review` | Parallel | 3 | Risk + Execution + Backtest |
| `critical_decision` | Consensus | 3 | Multi-perspective voting |
| `implementation_pipeline` | Sequential | 4 | Research â†’ Plan â†’ Implement â†’ Review |

### Workflow Patterns

**Parallel**: All agents run simultaneously

```python
Task(model="haiku", prompt="Security scan...")
Task(model="haiku", prompt="Type check...")
Task(model="sonnet", prompt="Architecture review...")
# All three start immediately
```

**Sequential**: Output chains to next agent

```text
Research Agent â†’ Plan Agent â†’ Implement Agent â†’ Review Agent
```

**Consensus**: Multiple agents vote independently

```text
Agent 1: APPROVE (85% confidence)
Agent 2: APPROVE (70% confidence)
Agent 3: NEEDS_MORE_INFO
Result: 66% consensus â†’ APPROVED
```

### Using the Task Tool

```python
Task(
    subagent_type="Explore",    # or "Plan", "general-purpose"
    model="haiku",              # or "sonnet", "opus"
    description="Short desc",   # 5-10 words
    prompt="Detailed task..."   # Full instructions
)
```

### Agent Templates

**Search Agents** (haiku):

- `CodeFinder` - Search source code
- `DocFinder` - Search documentation
- `TestFinder` - Search test files

**Review Agents** (haiku/sonnet):

- `SecurityScanner` - Vulnerability scanning
- `TypeChecker` - Type hint validation
- `TestAnalyzer` - Coverage analysis
- `Architect` - Architecture review

**Trading Agents** (sonnet):

- `RiskReviewer` - Risk management check
- `ExecutionReviewer` - Order execution review
- `BacktestReviewer` - Look-ahead bias check

**Deep Analysis** (opus):

- `DeepArchitect` - Comprehensive architecture
- `CriticalReviewer` - Production code review

### Cost-Effective Strategies

1. **Search tasks**: Always use `haiku` (fastest, cheapest)
2. **Batch searches**: Spawn 3-8 haiku agents in parallel
3. **Code review**: `haiku` for checks, `sonnet` for recommendations
4. **Critical decisions**: Use `sonnet` for consensus, `opus` only when required
5. **Implementation**: `haiku` research + `sonnet` implementation

### Files

| File | Purpose |
|------|---------|
| `.claude/hooks/agents/agent_orchestrator.py` | **Main orchestration engine** (1000+ lines) |
| `.claude/config/agents.json` | Configuration and preferences |
| `.claude/commands/agents.md` | Master `/agents` command |
| `.claude/commands/agent-auto.md` | Intelligent auto-routing |
| `.claude/commands/agent-quick.md` | Single agent dispatch |
| `.claude/commands/agent-swarm.md` | Massive parallel exploration |
| `.claude/commands/agent-consensus.md` | Multi-agent voting |
| `.claude/commands/agent-implement.md` | Implementation pipeline |
| `.claude/commands/agent-compare.md` | Option comparison |
| `.claude/commands/agent-status.md` | System status |

### CLI Usage

```bash
# Show help
python3 .claude/hooks/agents/agent_orchestrator.py help

# List all workflows and agents
python3 .claude/hooks/agents/agent_orchestrator.py list

# Auto-select agents for a task
python3 .claude/hooks/agents/agent_orchestrator.py auto "find all auth code"

# Generate Task calls for a workflow
python3 .claude/hooks/agents/agent_orchestrator.py generate code_review

# Show statistics
python3 .claude/hooks/agents/agent_orchestrator.py status
```

---

## Resources

### Project Documentation

- [QuantConnect GitHub Resources Guide](docs/development/QUANTCONNECT_GITHUB_GUIDE.md) - **START HERE** for LEAN architecture, Algorithm Framework patterns, options examples, and official code patterns
- [Development Best Practices](docs/development/BEST_PRACTICES.md) - Trading safety, risk management, backtesting standards
- [Coding Standards](docs/development/CODING_STANDARDS.md) - Style guide, type hints, error handling
- [Strategy Documentation](docs/strategies/README.md) - Trading strategy details
- [Infrastructure Setup](docs/infrastructure/SETUP_SUMMARY.md) - Compute nodes, Object Store, data subscriptions
- [Autonomous Agents Guide](docs/autonomous-agents/README.md) - Overnight session setup
- [Research Documentation](docs/research/README.md) - **Research index** for QuantConnect platform and evaluation framework research
- [Workflow Enhancement Research](docs/research/WORKFLOW_ENHANCEMENT_RESEARCH_DEC2025.md) - **2025 best practices** for code quality, testing, security
- [UPGRADE-009 Checklist](docs/research/UPGRADE-009-WORKFLOW-ENHANCEMENTS.md) - Implementation checklist for workflow improvements
- [Evaluation Framework Guide](evaluation/README.md) - **Evaluation system** with 7 integrated methodologies

### External References

- [QuantConnect Documentation](https://www.quantconnect.com/docs)
- [LEAN Engine GitHub](https://github.com/QuantConnect/Lean)
- [QuantConnect Forum](https://www.quantconnect.com/forum)
- [Claude Code Documentation](https://docs.anthropic.com/claude-code)
- [Charles Schwab API](https://developer.schwab.com/)
